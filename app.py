import os
import base64
import logging
import gradio as gr
from client.zhipu_llm import ZhipuLLM
import datetime
from rag.zhipu_knowledge_manager import get_zhipu_knowledge_manager
from config.config import Config
import json

KEY_MAP = {
    "ç©ºè…¹è¡€ç³–":       "ç©ºè…¹è¡€ç³–(GLUO)",
    "åŠå°æ—¶è¡€ç³–":     "åŠå°æ—¶è¡€ç³–(GLU0.5)",   # å¦‚æœè§£æå™¨è¾“å‡ºâ€œåŠå°æ—¶è¡€ç³–â€æƒ³å¡«åˆ°â€œäºŒå°æ—¶è¡€ç³–(GLU2)â€é‡Œï¼Œè¯·æŒ‰éœ€è°ƒæ•´
    "ä¸€å°æ—¶è¡€ç³–":     "ä¸€å°æ—¶è¡€ç³–(GLU1)",
    "ä¸¤å°æ—¶è¡€ç³–":     "ä¸¤å°æ—¶è¡€ç³–(GLU2)",
    "ä¸‰å°æ—¶è¡€ç³–":     "ä¸‰å°æ—¶è¡€ç³–(GLU3)",
    "ç³–åŒ–è¡€çº¢è›‹ç™½":   "ç³–åŒ–è¡€çº¢è›‹ç™½(HbA1C)",
    "ç©ºè…¹è¡€ç³–(GLUO)": "ç©ºè…¹è¡€ç³–",
    "åŠå°æ—¶è¡€ç³–(GLUO0.5)":     "åŠå°æ—¶è¡€ç³–",   # å¦‚æœè§£æå™¨è¾“å‡ºâ€œåŠå°æ—¶è¡€ç³–â€æƒ³å¡«åˆ°â€œäºŒå°æ—¶è¡€ç³–(GLU2)â€é‡Œï¼Œè¯·æŒ‰éœ€è°ƒæ•´
    "ä¸€å°æ—¶è¡€ç³–(GLU1)":     "ä¸€å°æ—¶è¡€ç³–",
    "ä¸¤å°æ—¶è¡€ç³–(GLU2)":     "ä¸¤å°æ—¶è¡€ç³–",
    "ä¸‰å°æ—¶è¡€ç³–(GLU3)":     "ä¸‰å°æ—¶è¡€ç³–",
    "ç³–åŒ–è¡€çº¢è›‹ç™½(HbA1C)":   "ç³–åŒ–è¡€çº¢è›‹ç™½",
    "BMI":           "BMI",
    "èº«é«˜":           None,  # ä¸éœ€è¦æç¤ºæ—¶å¯è®¾ä¸º None
    "ä½“é‡":           None,
    "æ”¶ç¼©å‹":         "è¡€å‹æ”¶ç¼©å‹",
    "èˆ’å¼ å‹":         "è¡€å‹èˆ’å¼ å‹",
    "å¿ƒç‡":           "é™æ¯å¿ƒç‡",
    "ä½“æ¸©":           "ä½“æ¸©",
    # â€¦â€¦å¦‚æœ‰å…¶å®ƒå­—æ®µï¼ŒæŒ‰å®é™…è¡¥å……
}

INDICATORS = {
    "ç—‡çŠ¶": {
        "prompt":
            "ä¸ºäº†æ›´å¥½åœ°äº†è§£æ‚¨çš„æƒ…å†µï¼Œ"
            "è¯·æ‚¨å›æƒ³æœ€è¿‘æ˜¯å¦å‡ºç°ä»¥ä¸‹ç—‡çŠ¶â€”â€”"
            "å¦‚å£æ¸´ã€æ’å°¿å¢å¤šæˆ–é£Ÿé‡æ˜æ˜¾å¢åŠ ï¼Ÿ",
        "value": None
    },
    "ç©ºè…¹è¡€ç³–": {
        "prompt":
            "æ¸…æ™¨ç©ºè…¹æ—¶ï¼ˆæœªè¿›é£Ÿè‡³å°‘8å°æ—¶ï¼‰ï¼Œ"
            "æ‚¨çš„è¡€ç³–å¤§çº¦æ˜¯å¤šå°‘ï¼Ÿ"
            "è¯·ç›´æ¥è¾“å…¥æ•°å€¼ï¼ˆmmol/Lï¼‰ã€‚",
        "value": None
    },
    "ä¸¤å°æ—¶è¡€ç³–": {
        "prompt": "åœ¨è¿›é¤åä¸¤å°æ—¶å†…æµ‹å¾—çš„è¡€ç³–å€¼æ˜¯å¤šå°‘ï¼Ÿ",
        "value": None
    },
    "ç³–åŒ–è¡€çº¢è›‹ç™½": {
        "prompt": "æœ€è¿‘ä¸€æ¬¡ç³–åŒ–è¡€çº¢è›‹ç™½ï¼ˆHbA1cï¼‰æ£€æµ‹ç»“æœæ˜¯å¤šå°‘ï¼Ÿ",
        "value": None
    },
    "BMI": {
        "prompt":
            "BMIï¼ˆä½“è´¨æŒ‡æ•°ï¼‰ç”¨äºè¯„ä¼°ä½“é‡æ˜¯å¦åœ¨å¥åº·èŒƒå›´ï¼Œ"
            "ä¸ç³–å°¿ç—…é£é™©å¯†åˆ‡ç›¸å…³ã€‚"
            "è¯·æ‚¨å‘Šè¯‰æˆ‘æ‚¨çš„ BMI å€¼ï¼ˆkg/mÂ²ï¼Œä»…æ•°å­—ï¼‰ï¼Œ",
        "value": None
    },
    "è¡€å‹æ”¶ç¼©å‹": {
        "prompt": "è¯·æä¾›æ”¶ç¼©å‹ SBPï¼ˆmmHgï¼Œä»…æ•°å­—ï¼‰",
        "value": None
    },
    "è¡€å‹èˆ’å¼ å‹": {
        "prompt": "è¯·æä¾›èˆ’å¼ å‹ DBPï¼ˆmmHgï¼Œä»…æ•°å­—ï¼‰",
        "value": None
    },
    "é™æ¯å¿ƒç‡": {
        "prompt": "è¯·æä¾›é™æ¯å¿ƒç‡ HRï¼ˆæ¬¡/åˆ†ï¼Œä»…æ•°å­—ï¼‰",
        "value": None
    },
    "äº²å±ç³–å°¿ç—…ç—…å²": {
        "prompt": "æ‚¨æ˜¯å¦æœ‰ä¸€çº§äº²å±ç³–å°¿ç—…ç—…å²æˆ–è€…å®¶æ—å²ï¼Ÿ",
        "value": None
    },
    "å…¶ä»–é‡è¦è¯´æ˜": {
        "prompt":
            "å¦‚æœæ‚¨æœ‰æ­£åœ¨ä½¿ç”¨çš„è¯ç‰©ã€ç‰¹æ®Šé¥®é£Ÿæˆ–è¿åŠ¨ä¹ æƒ¯ç­‰ï¼Œ"
            "è¿™ä¼šå¸®åŠ©æˆ‘ä»¬æ›´å…¨é¢åœ°äº†è§£æ‚¨çš„å¥åº·çŠ¶å†µã€‚"
            "è¯·æ‚¨è¡¥å……å…¶ä»–é‡è¦è¯´æ˜ï¼š",
        "value": None
    }
}



KEY_MAP = {
    "ç©ºè…¹è¡€ç³–":       "ç©ºè…¹è¡€ç³–(GLUO)",
    "åŠå°æ—¶è¡€ç³–":     "åŠå°æ—¶è¡€ç³–(GLU0.5)",   # å¦‚æœè§£æå™¨è¾“å‡ºâ€œåŠå°æ—¶è¡€ç³–â€æƒ³å¡«åˆ°â€œäºŒå°æ—¶è¡€ç³–(GLU2)â€é‡Œï¼Œè¯·æŒ‰éœ€è°ƒæ•´
    "ä¸€å°æ—¶è¡€ç³–":     "ä¸€å°æ—¶è¡€ç³–(GLU1)",
    "ä¸¤å°æ—¶è¡€ç³–":     "ä¸¤å°æ—¶è¡€ç³–(GLU2)",
    "ä¸‰å°æ—¶è¡€ç³–":     "ä¸‰å°æ—¶è¡€ç³–(GLU3)",
    "ç³–åŒ–è¡€çº¢è›‹ç™½":   "ç³–åŒ–è¡€çº¢è›‹ç™½(HbA1C)",
    "ç©ºè…¹è¡€ç³–(GLUO)": "ç©ºè…¹è¡€ç³–",
    "åŠå°æ—¶è¡€ç³–(GLUO0.5)":     "åŠå°æ—¶è¡€ç³–",   # å¦‚æœè§£æå™¨è¾“å‡ºâ€œåŠå°æ—¶è¡€ç³–â€æƒ³å¡«åˆ°â€œäºŒå°æ—¶è¡€ç³–(GLU2)â€é‡Œï¼Œè¯·æŒ‰éœ€è°ƒæ•´
    "ä¸€å°æ—¶è¡€ç³–(GLU1)":     "ä¸€å°æ—¶è¡€ç³–",
    "ä¸¤å°æ—¶è¡€ç³–(GLU2)":     "ä¸¤å°æ—¶è¡€ç³–",
    "ä¸‰å°æ—¶è¡€ç³–(GLU3)":     "ä¸‰å°æ—¶è¡€ç³–",
    "ç³–åŒ–è¡€çº¢è›‹ç™½(HbA1C)":   "ç³–åŒ–è¡€çº¢è›‹ç™½",
    "BMI":           "BMI",
    "èº«é«˜":           None,  # ä¸éœ€è¦æç¤ºæ—¶å¯è®¾ä¸º None
    "ä½“é‡":           None,
    "æ”¶ç¼©å‹":         "è¡€å‹æ”¶ç¼©å‹",
    "èˆ’å¼ å‹":         "è¡€å‹èˆ’å¼ å‹",
    "å¿ƒç‡":           "é™æ¯å¿ƒç‡",
    "ä½“æ¸©":           "ä½“æ¸©",
    # â€¦â€¦å¦‚æœ‰å…¶å®ƒå­—æ®µï¼ŒæŒ‰å®é™…è¡¥å……
}

INDICATORS = {
    "ç—‡çŠ¶": {
        "prompt":
            "ä¸ºäº†æ›´å¥½åœ°äº†è§£æ‚¨çš„æƒ…å†µï¼Œ"
            "è¯·æ‚¨å›æƒ³æœ€è¿‘æ˜¯å¦å‡ºç°ä»¥ä¸‹ç—‡çŠ¶â€”â€”"
            "å¦‚å£æ¸´ã€æ’å°¿å¢å¤šæˆ–é£Ÿé‡æ˜æ˜¾å¢åŠ ï¼Ÿ",
        "value": None
    },
    "ç©ºè…¹è¡€ç³–": {
        "prompt":
            "æ¸…æ™¨ç©ºè…¹æ—¶ï¼ˆæœªè¿›é£Ÿè‡³å°‘8å°æ—¶ï¼‰ï¼Œ"
            "æ‚¨çš„è¡€ç³–å¤§çº¦æ˜¯å¤šå°‘ï¼Ÿ"
            "è¯·ç›´æ¥è¾“å…¥æ•°å€¼ï¼ˆmmol/Lï¼‰ã€‚",
        "value": None
    },
    "ä¸¤å°æ—¶è¡€ç³–": {
        "prompt": "åœ¨è¿›é¤åä¸¤å°æ—¶å†…æµ‹å¾—çš„è¡€ç³–å€¼æ˜¯å¤šå°‘ï¼Ÿ",
        "value": None
    },
    "ç³–åŒ–è¡€çº¢è›‹ç™½": {
        "prompt": "æœ€è¿‘ä¸€æ¬¡ç³–åŒ–è¡€çº¢è›‹ç™½ï¼ˆHbA1cï¼‰æ£€æµ‹ç»“æœæ˜¯å¤šå°‘ï¼Ÿ",
        "value": None
    },
    "BMI": {
        "prompt":
            "BMIï¼ˆä½“è´¨æŒ‡æ•°ï¼‰ç”¨äºè¯„ä¼°ä½“é‡æ˜¯å¦åœ¨å¥åº·èŒƒå›´ï¼Œ"
            "ä¸ç³–å°¿ç—…é£é™©å¯†åˆ‡ç›¸å…³ã€‚"
            "è¯·æ‚¨å‘Šè¯‰æˆ‘æ‚¨çš„ BMI å€¼ï¼ˆkg/mÂ²ï¼Œä»…æ•°å­—ï¼‰ï¼Œ",
        "value": None
    },
    "è¡€å‹æ”¶ç¼©å‹": {
        "prompt": "è¯·æä¾›æ”¶ç¼©å‹ SBPï¼ˆmmHgï¼Œä»…æ•°å­—ï¼‰",
        "value": None
    },
    "è¡€å‹èˆ’å¼ å‹": {
        "prompt": "è¯·æä¾›èˆ’å¼ å‹ DBPï¼ˆmmHgï¼Œä»…æ•°å­—ï¼‰",
        "value": None
    },
    "é™æ¯å¿ƒç‡": {
        "prompt": "è¯·æä¾›é™æ¯å¿ƒç‡ HRï¼ˆæ¬¡/åˆ†ï¼Œä»…æ•°å­—ï¼‰",
        "value": None
    },
    "äº²å±ç³–å°¿ç—…ç—…å²": {
        "prompt": "æ‚¨æ˜¯å¦æœ‰ä¸€çº§äº²å±ç³–å°¿ç—…ç—…å²æˆ–è€…å®¶æ—å²ï¼Ÿ",
        "value": None
    },
    "å…¶ä»–é‡è¦è¯´æ˜": {
        "prompt":
            "å¦‚æœæ‚¨æœ‰æ­£åœ¨ä½¿ç”¨çš„è¯ç‰©ã€ç‰¹æ®Šé¥®é£Ÿæˆ–è¿åŠ¨ä¹ æƒ¯ç­‰ï¼Œ"
            "è¿™ä¼šå¸®åŠ©æˆ‘ä»¬æ›´å…¨é¢åœ°äº†è§£æ‚¨çš„å¥åº·çŠ¶å†µã€‚"
            "è¯·æ‚¨è¡¥å……å…¶ä»–é‡è¦è¯´æ˜ï¼š",
        "value": None
    }
}


logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s: %(message)s"
)
logger = logging.getLogger(__name__)
llm = ZhipuLLM()

DATA_DIR = os.path.join(os.path.dirname(__file__), "data")
os.makedirs(DATA_DIR, exist_ok=True)

# CSSï¼šå·¦ä¾§ Ã— å›¾æ ‡ & æ‚¬åœé«˜äº®
css = """
#file-selector .gr-checkbox {
  padding: 8px 8px 8px 28px;
  position: relative;
  border-radius: 4px;
  transition: background-color 0.2s;
}
/* Ã— å›¾æ ‡æ”¾åœ¨å·¦ä¾§ */
#file-selector .gr-checkbox:hover::before {
  content: "Ã—";
  position: absolute;
  left: 8px;
  top: 50%;
  transform: translateY(-50%);
  color: #e00;
  font-size: 16px;
  cursor: pointer;
}
/* æ‚¬åœé«˜äº® */
#file-selector .gr-checkbox:hover {
  background-color: #f5f5f5;
}
/* é™åˆ¶æ¸…é™¤æŒ‰é’®å®½åº¦ */
#clear-btn {
  min-width: 30px;
  max-width: 60px;
}
"""
# æ–°å¢ï¼šçŸ¥è¯†åº“å¢é‡/å¤ç”¨æœºåˆ¶
config = Config.get_instance()
kb_manager = get_zhipu_knowledge_manager()
knowledge_base_path = config.get_with_nested_params("Knowledge-base-path")

# è·å–æˆ–æ›´æ–°çŸ¥è¯†åº“IDï¼ˆå¦‚æœ‰æ–°æ–‡ä»¶åˆ™æ–°å»ºï¼Œå¦åˆ™å¤ç”¨ï¼‰
def get_or_update_knowledge_id():
    # å…ˆæŸ¥æ‰¾æœ¬åœ°å·²å­˜åœ¨çŸ¥è¯†åº“
    knowledge_list = kb_manager.get_knowledge_base_list()
    knowledge_id = None
    if knowledge_list:
        # é»˜è®¤ç”¨ç¬¬ä¸€ä¸ªçŸ¥è¯†åº“
        knowledge_id = knowledge_list[0]["id"]
    # æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ–‡ä»¶éœ€è¦ä¸Šä¼ 
    upload_results = {}
    if knowledge_id:
        upload_results = kb_manager.upload_directory_to_knowledge_base(
            knowledge_id, knowledge_base_path
        )
        # å¦‚æœæœ‰æ–°æ–‡ä»¶ä¸Šä¼ å¤±è´¥ï¼Œæˆ–å…¨éƒ¨å·²å­˜åœ¨ï¼Œåˆ™ç›´æ¥ç”¨æ—§ID
        if any(upload_results.values()):
            return knowledge_id
    # å¦‚æœæ²¡æœ‰çŸ¥è¯†åº“æˆ–å…¨éƒ¨ä¸Šä¼ å¤±è´¥ï¼Œåˆ™æ–°å»º
    if not knowledge_id or not any(upload_results.values()):
        knowledge_id = kb_manager.create_knowledge_base(
            name="ç³–å°¿ç—…æ™ºèƒ½é—®ç­”çŸ¥è¯†åº“",
            description="åŒ…å«ç³–å°¿ç—…ç›¸å…³çŸ¥è¯†ã€æ„å›¾æ£€æµ‹ç­‰å†…å®¹çš„ç»¼åˆçŸ¥è¯†åº“"
        )
        kb_manager.upload_directory_to_knowledge_base(
            knowledge_id, knowledge_base_path
        )
    return knowledge_id

def get_latest_knowledge_id():
    """ä» knowledge_info.json è·å–æœ€æ–°çŸ¥è¯†åº“ID"""
    info_path = os.path.join(DATA_DIR, "knowledge_info.json")
    if not os.path.exists(info_path):
        return None
    with open(info_path, "r", encoding="utf-8") as f:
        info = json.load(f)
    if not info:
        return None
    # å–æœ€åä¸€ä¸ªkeyï¼ˆæœ€æ–°åˆ›å»ºï¼‰
    latest_id = list(info.keys())[-1]
    return latest_id

def on_file_upload(file_paths, history, file_list):
    history   = history   or []
    file_list = file_list or []

    # å¦‚æœæ²¡é€‰æ–°æ–‡ä»¶ï¼Œä»…åˆ·æ–°åˆ—è¡¨
    if not file_paths:
        opts = [os.path.basename(p) for p in file_list]
        return history, history, file_list, gr.update(choices=opts, value=[])

    paths = file_paths if isinstance(file_paths, list) else [file_paths]

    from tools.lab_report_parser import parse_lab_report

    for p in paths:
        if p in file_list:
            continue
        file_list.append(p)
        name = os.path.basename(p)
        ext  = os.path.splitext(name)[1].lower().lstrip(".")

        with open(p, "rb") as f:
            file_bytes = f.read()
            b64 = base64.b64encode(file_bytes).decode("utf-8")

        # èŠå¤©åŒºæ’å…¥å›¾ç‰‡/æ–‡ä»¶
        if ext in ("png","jpg","jpeg"):
            md = f"![{name}](data:image/{ext};base64,{b64})"
            history.append({"role":"system", "content":f"å·²ä¸Šä¼ å›¾ç‰‡ï¼š{name}\n\n{md}"})
            # è‡ªåŠ¨è§£æå›¾ç‰‡åŒ»å­¦æŒ‡æ ‡
            result = parse_lab_report(file_bytes)
            print(result)
            # è‡ªåŠ¨éå†æ‰€æœ‰éç©ºåŒ»å­¦æŒ‡æ ‡å¹¶å±•ç¤ºï¼ˆç›´æ¥ç”¨ä¸­æ–‡keyï¼‰
            if any(result.values()):
                summary = []
                user_features = {}
                # keyæ˜ å°„ï¼šä¸­æ–‡key->æ•°æ®é›†è‹±æ–‡key
                key_map = {
                    "æ€§åˆ«": "gender",
                    "å¹´é¾„": "age",
                    "é«˜è¡€å‹": "hypertension",
                    "å¿ƒè„ç—…": "heart_disease",
                    "å¸çƒŸå²": "smoking_history",
                    "BMI": "bmi",
                    "ç³–åŒ–è¡€çº¢è›‹ç™½": "HbA1c_level",
                    "ç©ºè…¹è¡€ç³–": "blood_glucose_level",
                    "ä¸¤å°æ—¶è¡€ç³–": "blood_glucose_level",
                    "ç³–å°¿ç—…": "diabetes",
                    # å¯æ ¹æ®å®é™…æ•°æ®é›†ç»§ç»­è¡¥å……
                }
                import re
                for k, v in result.items():
                    if v is not None:
                        summary.append(f"{k}: {v}")
<<<<<<< HEAD
                        mapped_key = key_map.get(k, k)
                        num = None
                        try:
                            num = float(v)
                        except Exception:
                            match = re.search(r"[-+]?[0-9]*\\.?[0-9]+", str(v))
                            if match:
                                try:
                                    num = float(match.group())
                                except Exception:
                                    pass
                        if num is not None:
                            user_features[mapped_key] = num
                        # è‡ªåŠ¨å¡«å……åˆ°INDICATORS valueå­—æ®µ
                        if k in INDICATORS and v not in (None, ""):
                            INDICATORS[k]["value"] = str(v)
=======
                    if k in INDICATORS and v not in ("", None):
                        INDICATORS[k]["value"] = str(v)
                print(INDICATORS)
>>>>>>> origin/master
                if summary:
                    history.append({"role": "system", "content": "è‡ªåŠ¨è¯†åˆ«ä¿¡æ¯ï¼š\n" + "\\n".join(summary)})
                # è‡ªåŠ¨è§¦å‘RAGæ£€ç´¢
                if user_features:
                    from rag.index_diabetes import generate_scientific_advice
                    rag_info = generate_scientific_advice(user_features)
                    history.append({"role": "system", "content": "ã€æ•°æ®é›†ç›¸ä¼¼ç—…ä¾‹å‚è€ƒã€‘\n" + rag_info})
        elif ext == "pdf":
            md = f"[ğŸ“„ {name}](data:application/pdf;base64,{b64})"
            history.append({"role":"system","content":f"å·²ä¸Šä¼  PDFï¼š{md}"})
            # è‡ªåŠ¨è§£æ PDF åŒ»å­¦æŒ‡æ ‡
            result = parse_lab_report(file_bytes)
            if any(result.values()):
                summary = []
                for k, v in result.items():
                    if v is not None:
                        summary.append(f"{k}: {v}")
                if summary:
                    history.append({"role": "system", "content": "è‡ªåŠ¨è¯†åˆ«ä¿¡æ¯ï¼š\n" + "\n".join(summary)})
        else:
            history.append({"role":"system","content":f"å·²ä¸Šä¼ æ–‡ä»¶ï¼š{name}"})

    opts = [os.path.basename(p) for p in file_list]
    return history, history, file_list, gr.update(choices=opts, value=[])

def on_delete(selected, file_list):
    # ç‚¹å‡»å‹¾é€‰å³åˆ é™¤
    file_list = file_list or []
    remaining = [p for p in file_list if os.path.basename(p) not in (selected or [])]
    opts = [os.path.basename(p) for p in remaining]
    return remaining, gr.update(choices=opts, value=[])

def on_send(text, file_list, history, name, age, weight, gender, past_history):
    history   = history or []
    user_msg  = text or ""

    if file_list:
        names = ", ".join(os.path.basename(p) for p in file_list)
        suffix = f"[å·²ä¸Šä¼ æ–‡ä»¶ï¼š{names}]"
        user_msg = f"{user_msg}\n{suffix}" if user_msg else suffix
    history.append({"role":"user","content":user_msg})

    
<<<<<<< HEAD
    # ä¼˜å…ˆåˆ¤æ–­æ˜¯å¦æœ‰è‡ªåŠ¨è¯†åˆ«çš„æ•°å€¼å‹æŒ‡æ ‡
    auto_features = {}
    for key, info in INDICATORS.items():
        value = info["value"]
        try:
            num = float(value)
            auto_features[key] = num
        except Exception:
            pass
    if auto_features:
        # å·²æœ‰è‡ªåŠ¨è¯†åˆ«æ•°å€¼ï¼Œç›´æ¥è¿›å…¥LLMå»ºè®®å’ŒRAG
        pass
    else:
        # æ²¡æœ‰è‡ªåŠ¨è¯†åˆ«æ•°å€¼ï¼Œé€é¡¹é—®è¯¢
        for key, info in INDICATORS.items():
            prompt_text = info["prompt"]
            value = info["value"]
            print(f"æŒ‡æ ‡åï¼š{key}ï¼Œæç¤ºè¯­ï¼š{prompt_text}ï¼Œå·²å¡«å€¼ï¼š{value}")
            if value is None:
                history.append({
                    "role": "assistant",
                    "content": prompt_text
                })
                INDICATORS[key]["value"] = user_msg
                return (
                    history,                                     
                    history,                                     
                    file_list,                                   
                    gr.update(choices=[os.path.basename(p) for p in file_list], value=[]), 
                    gr.update(value="")                         
                )
=======
    for key, info in INDICATORS.items():
        prompt_text = info["prompt"]
        value = info["value"]
        # æ‰“å°è°ƒè¯•ä¿¡æ¯å¯é€‰
        print(f"æŒ‡æ ‡åï¼š{key}ï¼Œæç¤ºè¯­ï¼š{prompt_text}ï¼Œå·²å¡«å€¼ï¼š{value}")
        if value is None:
            # æŠŠè¿™ä¸ªæŒ‡æ ‡çš„ prompt å‘ç»™ç”¨æˆ·
            history.append({
                "role": "assistant",
                "content": prompt_text
            })
            INDICATORS[key]["value"] = user_msg
            return (
                history,                                     
                history,                                     
                file_list,                                    
                gr.update(choices=[os.path.basename(p) for p in file_list], value=[]), 
                gr.update(value="")                          
            )
>>>>>>> origin/master

    # ä»…æ‹¼æ¥å·²ä¸Šä¼ æ–‡ä»¶ä¿¡æ¯
    if file_list:
        names = ", ".join(os.path.basename(p) for p in file_list)
        user_msg = (user_msg + "\n" if user_msg else "") + f"[å·²ä¸Šä¼ æ–‡ä»¶ï¼š{names}]"
<<<<<<< HEAD
    # ç”¨æˆ·æ¶ˆæ¯ç›´æ¥ä¼ é€’ï¼ˆå‰ç«¯ä¸æ˜¾ç¤ºä¸ªäººä¿¡æ¯ï¼‰
    history.append({"role":"user","content":user_msg})
=======
>>>>>>> origin/master

    # æ‹¼æ¥ä¸ªäººä¿¡æ¯ï¼ˆåç«¯ä¼ ç»™æ¨¡å‹ï¼Œä¸æ˜¾ç¤ºåœ¨èŠå¤©åŒºï¼‰
    personal_info = (
        f"å§“åï¼š{name or 'æœªå¡«å†™'}ï¼›å¹´é¾„ï¼š{age or 'æœªå¡«å†™'}ï¼›ä½“é‡ï¼š{weight or 'æœªå¡«å†™'}ï¼›"
        f"æ€§åˆ«ï¼š{gender or 'æœªå¡«å†™'}ï¼›æ—¢å¾€å²ï¼š{past_history or 'æœªå¡«å†™'}"
    )

    # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡/æŠ¥å‘Šè‡ªåŠ¨è¯†åˆ«ä¿¡æ¯
    auto_info = None
    for m in reversed(history):
        if m["role"] == "system" and m["content"].startswith("è‡ªåŠ¨è¯†åˆ«ä¿¡æ¯ï¼š"):
            auto_info = m["content"]
            break

    # LLM å»ºè®®
    if auto_info:
<<<<<<< HEAD
        # ä»historyä¸­æŸ¥æ‰¾ragæ£€ç´¢ç»“æœ
        rag_info = ''
        for m in reversed(history):
            if m["role"] == "system" and m["content"].startswith("ã€æ•°æ®é›†ç›¸ä¼¼ç—…ä¾‹å‚è€ƒã€‘"):
                rag_info = m["content"]
                break
        if rag_info:
            rag_info = f"{rag_info}\n"
        prompt = (
            f"ç”¨æˆ·ä¸ªäººä¿¡æ¯ï¼š{personal_info}\n"
            f"ç”¨æˆ·ä¸Šä¼ äº†åŒ»å­¦æŠ¥å‘Šæˆ–å›¾ç‰‡ï¼Œç³»ç»Ÿè‡ªåŠ¨è¯†åˆ«å‡ºå¦‚ä¸‹ç»“æ„åŒ–ä¿¡æ¯ï¼š\n{auto_info}\n"
            f"{rag_info}"
=======
        prompt = (
            f"ç”¨æˆ·ä¸ªäººä¿¡æ¯ï¼š{personal_info}\n"
            f"ç”¨æˆ·ä¸Šä¼ äº†åŒ»å­¦æŠ¥å‘Šæˆ–å›¾ç‰‡ï¼Œç³»ç»Ÿè‡ªåŠ¨è¯†åˆ«å‡ºå¦‚ä¸‹ç»“æ„åŒ–ä¿¡æ¯ï¼š\n{auto_info}\n,å¹¶æ¢å¤åœ¨auto_infoä¸­äº†è§£äº†ä»€ä¹ˆ"
>>>>>>> origin/master
            f"è¯·åŸºäºè¿™äº›åŒ»å­¦ä¿¡æ¯ï¼Œç»“åˆç”¨æˆ·æ¶ˆæ¯â€œ{user_msg}â€ï¼Œå¹¶æ¢å¤åœ¨user_msgä¸­äº†è§£äº†ä»€ä¹ˆï¼Œä¸ç”¨è§£é‡Šäº†è§£çš„ä¿¡æ¯ã€‚"
            "å¦‚æœä¿¡æ¯ä¸å…¨å¯é€‚å½“è¯´æ˜ï¼Œä½†ä¸è¦è¯´æ— æ³•è¯†åˆ«å›¾ç‰‡ã€‚"
        )
    else:
        prompt = (
            f"ç”¨æˆ·ä¸ªäººä¿¡æ¯ï¼š{personal_info}\n"
            f"ç”¨æˆ·æ¶ˆæ¯ï¼š{user_msg}\nå¹¶æ¢å¤åœ¨user_msgä¸­äº†è§£äº†ä»€ä¹ˆï¼Œä¸ç”¨è§£é‡Šäº†è§£çš„ä¿¡æ¯ã€‚"
        )
    logger.info("Prompt to LLM: %s", prompt)
    # RAG æ£€ç´¢ï¼šè°ƒç”¨æ™ºæ™®çŸ¥è¯†åº“å¯¹è¯æ¥å£
    kb_id = get_or_update_knowledge_id()
    try:
        kb_reply = kb_manager.chat_with_knowledge_base(
            knowledge_id=kb_id,
            question=user_msg,
            stream=False
        )
    except Exception as e:
        kb_reply = f"çŸ¥è¯†åº“æ£€ç´¢å‡ºé”™ï¼š{e}"

    # æ„å»º Prompt
    prompt_parts = [f"ç”¨æˆ·ä¸ªäººä¿¡æ¯ï¼š{personal_info}"]
    if auto_info:
        prompt_parts.append(f"ç³»ç»Ÿè‡ªåŠ¨è¯†åˆ«ä¿¡æ¯ï¼š\n{auto_info}")
    prompt_parts.append(f"çŸ¥è¯†åº“å›å¤ï¼š\n{kb_reply}")
    prompt_parts.append(f"ç”¨æˆ·æ¶ˆæ¯ï¼š{user_msg}")
    prompt_parts.append("è¯·åŸºäºä¸Šè¿°ä¿¡æ¯ç»™å‡ºä¸“ä¸šã€å‡†ç¡®çš„ç³–å°¿ç—…ç®¡ç†å»ºè®®ã€‚")
    final_prompt = "\n".join(prompt_parts)
    logger.info("Final RAG Prompt to LLM: %s", final_prompt)

    # è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆæœ€ç»ˆå›å¤
    try:
        reply = llm._call(final_prompt)
    except Exception as e:
        reply = f"æ¨¡å‹è°ƒç”¨å‡ºé”™ï¼š{e}"
    history.append({"role": "assistant", "content": reply})

    # æ¸…ç©ºä¸Šä¼ åˆ—è¡¨
    return (
        history,
        history,
        [],
        gr.update(choices=[], value=[]),
        gr.update(value="")
    )


def on_generate_case(history, name=None, age=None, weight=None, gender=None, past_history=None):
    # åˆ¤æ–­ä¸ªäººä¿¡æ¯æ˜¯å¦å¡«å†™
    info_filled = any([name, age, weight, gender, past_history])
    # åˆ¤æ–­æ˜¯å¦æœ‰å¯¹è¯å†…å®¹ï¼ˆæ’é™¤åˆå§‹æ¬¢è¿è¯­ï¼‰
    dialog_filled = history and any(
        m["role"] == "user" and m["content"].strip() for m in history if m["role"] == "user"
    )

    # æƒ…å†µ1ï¼šä¸ªäººä¿¡æ¯å’Œå¯¹è¯éƒ½æ²¡æœ‰
    if not info_filled and not dialog_filled:
        return "æ²¡æœ‰ä¿¡æ¯å¯ä»¥ç”Ÿæˆç—…ä¾‹æŠ¥å‘Šå•ï¼Œè¯·å…ˆå¡«å†™ä¸ªäººä¿¡æ¯æˆ–è¿›è¡Œå¯¹è¯ã€‚"

    # æƒ…å†µ2ï¼šåªæœ‰ä¸ªäººä¿¡æ¯
    if info_filled and not dialog_filled:
        personal_info = (
            f"å§“åï¼š{name or 'æœªå¡«å†™'}\n"
            f"å¹´é¾„ï¼š{age or 'æœªå¡«å†™'}\n"
            f"ä½“é‡ï¼š{weight or 'æœªå¡«å†™'}\n"
            f"æ€§åˆ«ï¼š{gender or 'æœªå¡«å†™'}\n"
            f"æ—¢å¾€å²ï¼š{past_history or 'æœªå¡«å†™'}"
        )
        return f"**ç—…ä¾‹æŠ¥å‘Šå•**\n\n{personal_info}"

    # æƒ…å†µ3ï¼šåªæœ‰å¯¹è¯å†…å®¹
    if not info_filled and dialog_filled:
        personal_info = (
            f"å§“åï¼šæ— \nå¹´é¾„ï¼šæ— \nä½“é‡ï¼šæ— \næ€§åˆ«ï¼šæ— \næ—¢å¾€å²ï¼šæ— "
        )
        hist = "\n".join(f"{m['role']}: {m['content']}" for m in history)
        case_p = (
            f"è¯·æ ¹æ®ä»¥ä¸‹å¯¹è¯ç”Ÿæˆç»“æ„åŒ–ç³–å°¿ç—…ç—…ä¾‹ï¼š\n\n"
            f"{personal_info}\n\n{hist}\n\n"
            "ç—…ä¾‹åº”åŒ…æ‹¬ï¼šç”¨æˆ·ä¸ªäººä¿¡æ¯(å§“åï¼Œå¹´é¾„ï¼Œä½“é‡ï¼Œæ€§åˆ«)ã€ä¸»è¯‰ã€ç°ç—…å²ã€æ—¢å¾€å²ã€æ£€æŸ¥ç»“æœã€åˆæ­¥è¯Šæ–­ã€ç®¡ç†å»ºè®®ã€‚æ§åˆ¶å­—æ•°åœ¨500å­—ä¹‹å†…"
        )
        logger.info("Case prompt to LLM: %s", case_p)
        try:
            case = llm._call(case_p)
        except Exception as e:
            case = f"ç”Ÿæˆç—…ä¾‹å‡ºé”™ï¼š{e}"
            return case
        return case

    # æƒ…å†µ4ï¼šä¸ªäººä¿¡æ¯å’Œå¯¹è¯éƒ½æœ‰
    personal_info = (
        f"å§“åï¼š{name or 'æœªå¡«å†™'}ï¼›å¹´é¾„ï¼š{age or 'æœªå¡«å†™'}ï¼›ä½“é‡ï¼š{weight or 'æœªå¡«å†™'}ï¼›"
        f"æ€§åˆ«ï¼š{gender or 'æœªå¡«å†™'}ï¼›æ—¢å¾€å²ï¼š{past_history or 'æœªå¡«å†™'}"
    )
    hist = "\n".join(f"{m['role']}: {m['content']}" for m in history)
    case_p = (
        f"è¯·æ ¹æ®ä»¥ä¸‹å¯¹è¯å’Œä¸ªäººä¿¡æ¯ç”Ÿæˆç»“æ„åŒ–ç³–å°¿ç—…ç—…ä¾‹ï¼š\n\n"
        f"{personal_info}\n\n{hist}\n\n"
        "ç—…ä¾‹åº”åŒ…æ‹¬ï¼šç”¨æˆ·ä¸ªäººä¿¡æ¯(å§“åï¼Œå¹´é¾„ï¼Œä½“é‡ï¼Œæ€§åˆ«)ã€ä¸»è¯‰ã€ç°ç—…å²ã€æ—¢å¾€å²ã€æ£€æŸ¥ç»“æœã€åˆæ­¥è¯Šæ–­ã€ç®¡ç†å»ºè®®ã€‚æ§åˆ¶å­—æ•°åœ¨500å­—ä¹‹å†…"
    )
    logger.info("Case prompt to LLM: %s", case_p)
    try:
        case = llm._call(case_p)
    except Exception as e:
        case = f"ç”Ÿæˆç—…ä¾‹å‡ºé”™ï¼š{e}"
        return case
    return case

def on_clear_history():
    welcome_msg = [{"role": "assistant", "content": "æ‚¨å¥½ï¼Œæˆ‘æ˜¯ç³–å°¿ç—…ä¸“ä¸šåŠ©æ‰‹ï¼Œè¯·æ‚¨æä¾›è¯¦ç»†ç—…ä¾‹ä¿¡æ¯ï¼Œä»¥ä¾¿æˆ‘ä¸ºæ‚¨é‡èº«å®šåˆ¶åŒ»å­¦å»ºè®®ã€‚ä½ æœ‰å…³äºæœ€è¿‘çš„æŠ¥å‘Šå¯ä»¥ç»™æˆ‘çœ‹çœ‹å—"}]
    return welcome_msg, welcome_msg, "**ç—…ä¾‹è®°å½•**\n\nå°šæ— å†…å®¹"

with gr.Blocks(css=css) as demo:
    gr.Markdown("## ç³–å°¿ç—…åŠ©æ‰‹ ğŸ©¸ â€” å·¦ï¼šå¯¹è¯äº¤äº’ï¼›å³ï¼šç—…ä¾‹è®°å½•")

    # æ–°å¢ï¼šä¸ªäººä¿¡æ¯è¾“å…¥æ¡†
    with gr.Row():
        name_input = gr.Textbox(label="å§“å", placeholder="è¯·è¾“å…¥å§“å", lines=1)
        age_input = gr.Textbox(label="å¹´é¾„", placeholder="è¯·è¾“å…¥å¹´é¾„", lines=1)
        weight_input = gr.Textbox(label="ä½“é‡ï¼ˆkgï¼‰", placeholder="è¯·è¾“å…¥ä½“é‡", lines=1)
        gender_input = gr.Dropdown(label="æ€§åˆ«", choices=["ç”·", "å¥³"], value=None)
        history_input = gr.Textbox(label="æ—¢å¾€å²", placeholder="è¯·è¾“å…¥æ—¢å¾€å²", lines=1)

    # åˆå§‹å¼•å¯¼æ¶ˆæ¯
    initial_message = {
        "role": "assistant",
        "content": (
            "æ‚¨å¥½ï¼Œæˆ‘æ˜¯æ‚¨çš„æ™ºèƒ½ç³–å°¿ç—…å¥åº·ç®¡ç†åŠ©æ‰‹ï¼Œå¯ä»¥ä¸ºæ‚¨æä¾›ç³–å°¿ç—…ç›¸å…³çš„æ£€æµ‹è§£è¯»ã€å¥åº·å»ºè®®å’Œä¸ªæ€§åŒ–ç®¡ç†æ–¹æ¡ˆã€‚\n"
            "è¯·é—®æ‚¨çš„å§“åã€å¹´é¾„ã€æ€§åˆ«ã€ç³–å°¿ç—…ç±»å‹ã€è¯Šæ–­æ—¶é—´ç­‰åŸºæœ¬ä¿¡æ¯ï¼Œä»¥åŠç›®å‰çš„ä¸»è¦å¥åº·å…³æ³¨ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ"
        )
    }

    with gr.Row():
        # å·¦ä¾§å¯¹è¯åŒºåŸŸ
        with gr.Column(scale=3):
            chatbot = gr.Chatbot(type="messages", label="å¯¹è¯è®°å½•", height=500)
            with gr.Row():
                upload_btn = gr.UploadButton(
                    "ğŸ“ ä¸Šä¼ æ–‡ä»¶",
                    file_types=[".png",".jpg",".jpeg",".pdf"],
                    file_count="multiple",
                    type="filepath",
                    elem_id="upload-btn",
                    scale=1
                )
                text_input = gr.Textbox(
                    placeholder="è¯·è¾“å…¥é—®é¢˜æˆ–å¤‡æ³¨ï¼ˆå¯é€‰ï¼‰",
                    lines=1,
                    show_label=False,
                    elem_id="text-input",
                    scale=2
                )
                send_btn = gr.Button("å‘é€", elem_id="send-btn", scale=1)
            file_list = gr.State([])  # ç”¨äºå­˜å‚¨æ–‡ä»¶è·¯å¾„
            file_selector = gr.CheckboxGroup(
                choices=[],
                label="å·²ä¸Šä¼ æ–‡ä»¶ï¼ˆç‚¹å‡» Ã— åˆ é™¤ï¼‰",
                elem_id="file-selector"
            )
            with gr.Row():
                gr.Examples(
                    examples=[
                        "ç³–å°¿ç—…å¦‚ä½•æ§åˆ¶è¡€ç³–ï¼Ÿ",
                        "èƒ°å²›ç´ ä½¿ç”¨æ³¨æ„äº‹é¡¹ï¼Ÿ",
                        "ä½è¡€ç³–å¤„ç†æ–¹å¼",
                        "æˆ‘æœ€è¿‘è¡€ç³–æœ‰ç‚¹é«˜ï¼Œæ€ä¹ˆç¼“è§£ï¼Ÿ",
                        "ç³–å°¿ç—…é¥®é£Ÿæœ‰å“ªäº›ç¦å¿Œï¼Ÿ",
                        "è¿åŠ¨å¯¹è¡€ç³–å½±å“",
                        "å¦‚ä½•ç›‘æµ‹è¡€ç³–å˜åŒ–ï¼Ÿ",
                        "ç³–å°¿ç—…å¹¶å‘ç—‡æœ‰å“ªäº›ï¼Ÿ",
                        "èƒ°å²›ç´ æ³µçš„é€‚ç”¨æ€§",
                        "è¡€ç³–é«˜æœ‰å“ªäº›ç—‡çŠ¶ï¼Ÿ",
                    ],
                    inputs=[text_input]
                )
                clear_btn = gr.Button("æ¸…é™¤å¯¹è¯å†å²", elem_id="clear-btn", scale=1)

        # å³ä¾§ç—…ä¾‹è®°å½•
        with gr.Column(scale=2):
            case_md = gr.Markdown("**ç—…ä¾‹è®°å½•**\n\nå°šæ— å†…å®¹")
            gen_case_btn = gr.Button("ç”Ÿæˆç—…ä¾‹æŠ¥å‘Šå•", elem_id="gen-case-btn")

    state = gr.State([{"role": "assistant", "content": "æ‚¨å¥½ï¼Œæˆ‘æ˜¯ç³–å°¿ç—…ä¸“ä¸šåŠ©æ‰‹ï¼Œè¯·æ‚¨æä¾›è¯¦ç»†ç—…ä¾‹ä¿¡æ¯ï¼Œä»¥ä¾¿æˆ‘ä¸ºæ‚¨é‡èº«å®šåˆ¶åŒ»å­¦å»ºè®®ã€‚"}])

    # ä¸Šä¼  -> æ›´æ–°èŠå¤© & æ–‡ä»¶åˆ—è¡¨
    upload_btn.upload(
        fn=on_file_upload,
        inputs=[upload_btn, state, file_list],
        outputs=[chatbot, state, file_list, file_selector]
    )
    # å‹¾é€‰å³åˆ é™¤
    file_selector.change(
        fn=on_delete,
        inputs=[file_selector, file_list],
        outputs=[file_list, file_selector]
    )
    # å‘é€ -> ç”Ÿæˆå›å¤ï¼Œå¹¶æ¸…ç©ºæ–‡ä»¶åˆ—è¡¨å’Œè¾“å…¥æ¡†
    send_btn.click(
        fn=on_send,
        inputs=[text_input, file_list, state, name_input, age_input, weight_input, gender_input, history_input],
        outputs=[chatbot, state, file_list, file_selector, text_input]
    )
    text_input.submit(
        fn=on_send,
        inputs=[text_input, file_list, state, name_input, age_input, weight_input, gender_input, history_input],
        outputs=[chatbot, state, file_list, file_selector, text_input]
    )
    # æ¸…é™¤å¯¹è¯å†å²æŒ‰é’®
    clear_btn.click(
        fn=on_clear_history,
        inputs=None,
        outputs=[chatbot, state, case_md]
    )
    # ç”Ÿæˆç—…ä¾‹æŠ¥å‘Šå•æŒ‰é’®
    gen_case_btn.click(
        fn=on_generate_case,
        inputs=[state, name_input, age_input, weight_input, gender_input, history_input],
        outputs=[case_md]
    )

if __name__ == "__main__":
    demo.launch(inbrowser=True)
