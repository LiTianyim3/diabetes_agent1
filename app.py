import os,re
import base64
import logging
import gradio as gr
from client.zhipu_llm import ZhipuLLM
import datetime
from rag.zhipu_knowledge_manager import get_zhipu_knowledge_manager
from config.config import Config
import json

KEY_MAP = {
    "ç©ºè…¹è¡€ç³–":       "ç©ºè…¹è¡€ç³–(GLUO)",
    "åŠå°æ—¶è¡€ç³–":     "åŠå°æ—¶è¡€ç³–(GLU0.5)",   # å¦‚æœè§£æå™¨è¾“å‡ºâ€œåŠå°æ—¶è¡€ç³–â€æƒ³å¡«åˆ°â€œäºŒå°æ—¶è¡€ç³–(GLU2)â€é‡Œï¼Œè¯·æŒ‰éœ€è°ƒæ•´
    "ä¸€å°æ—¶è¡€ç³–":     "ä¸€å°æ—¶è¡€ç³–(GLU1)",
    "ä¸¤å°æ—¶è¡€ç³–":     "ä¸¤å°æ—¶è¡€ç³–(GLU2)",
    "ä¸‰å°æ—¶è¡€ç³–":     "ä¸‰å°æ—¶è¡€ç³–(GLU3)",
    "ç³–åŒ–è¡€çº¢è›‹ç™½":   "ç³–åŒ–è¡€çº¢è›‹ç™½(HbA1C)",
    "ç©ºè…¹è¡€ç³–(GLUO)": "ç©ºè…¹è¡€ç³–",
    "åŠå°æ—¶è¡€ç³–(GLUO0.5)":     "åŠå°æ—¶è¡€ç³–",   # å¦‚æœè§£æå™¨è¾“å‡ºâ€œåŠå°æ—¶è¡€ç³–â€æƒ³å¡«åˆ°â€œäºŒå°æ—¶è¡€ç³–(GLU2)â€é‡Œï¼Œè¯·æŒ‰éœ€è°ƒæ•´
    "ä¸€å°æ—¶è¡€ç³–(GLU1)":     "ä¸€å°æ—¶è¡€ç³–",
    "ä¸¤å°æ—¶è¡€ç³–(GLU2)":     "ä¸¤å°æ—¶è¡€ç³–",
    "ä¸‰å°æ—¶è¡€ç³–(GLU3)":     "ä¸‰å°æ—¶è¡€ç³–",
    "ç³–åŒ–è¡€çº¢è›‹ç™½(HbA1C)":   "ç³–åŒ–è¡€çº¢è›‹ç™½",
    "BMI":           "BMI",
    "èº«é«˜":           None,  # ä¸éœ€è¦æç¤ºæ—¶å¯è®¾ä¸º None
    "ä½“é‡":           None,
    "æ”¶ç¼©å‹":         "è¡€å‹æ”¶ç¼©å‹",
    "èˆ’å¼ å‹":         "è¡€å‹èˆ’å¼ å‹",
    "å¿ƒç‡":           "é™æ¯å¿ƒç‡",
    "ä½“æ¸©":           "ä½“æ¸©",
    # â€¦â€¦å¦‚æœ‰å…¶å®ƒå­—æ®µï¼ŒæŒ‰å®é™…è¡¥å……
}

INDICATORS = {
    "å¹´é¾„": {
        "prompt":
            "æˆ‘å·²ç»çœ‹åˆ°äº†æŠ¥å‘Šæ¥ä¸‹æ¥æˆ‘ä¼šé—®å‡ ä¸ªé—®é¢˜"
            "æ‚¨å¤šå¤§äº†",
        "value": None
    },
    "ç—‡çŠ¶": {
        "prompt":
            "ä¸ºäº†æ›´å¥½åœ°äº†è§£æ‚¨çš„æƒ…å†µï¼Œ"
            "è¯·æ‚¨å›æƒ³æœ€è¿‘æ˜¯å¦å‡ºç°ä»¥ä¸‹ç—‡çŠ¶â€”â€”"
            "å¦‚å£æ¸´ã€æ’å°¿å¢å¤šæˆ–é£Ÿé‡æ˜æ˜¾å¢åŠ ï¼Ÿ",
        "value": None
    },
    "ç©ºè…¹è¡€ç³–(GLU0)": {
        "prompt":
            "æ¸…æ™¨ç©ºè…¹æ—¶ï¼ˆæœªè¿›é£Ÿè‡³å°‘8å°æ—¶ï¼‰ï¼Œ"
            "æ‚¨çš„è¡€ç³–å¤§çº¦æ˜¯å¤šå°‘ï¼Ÿ"
            "è¯·ç›´æ¥è¾“å…¥æ•°å€¼ï¼ˆmmol/Lï¼‰ã€‚",
        "value": None
    },
    "äºŒå°æ—¶è¡€ç³–(GLU2)": {
        "prompt": "åœ¨è¿›é¤åä¸¤å°æ—¶å†…æµ‹å¾—çš„è¡€ç³–å€¼æ˜¯å¤šå°‘ï¼Ÿ",
        "value": None
    },
    "ç³–åŒ–è¡€çº¢è›‹ç™½(HbA1c)": {
        "prompt": "æœ€è¿‘ä¸€æ¬¡ç³–åŒ–è¡€çº¢è›‹ç™½ï¼ˆHbA1cï¼‰æ£€æµ‹ç»“æœæ˜¯å¤šå°‘ï¼Ÿ",
        "value": None
    },
    "BMI": {
        "prompt":
            "BMIï¼ˆä½“è´¨æŒ‡æ•°ï¼‰ç”¨äºè¯„ä¼°ä½“é‡æ˜¯å¦åœ¨å¥åº·èŒƒå›´ï¼Œ"
            "ä¸ç³–å°¿ç—…é£é™©å¯†åˆ‡ç›¸å…³ã€‚"
            "è¯·æ‚¨å‘Šè¯‰æˆ‘æ‚¨çš„ BMI å€¼ï¼ˆkg/mÂ²ï¼Œä»…æ•°å­—ï¼‰ï¼Œ",
        "value": None
    },
    "è¡€å‹æ”¶ç¼©å‹": {
        "prompt": "è¯·æä¾›æ”¶ç¼©å‹ SBPï¼ˆmmHgï¼Œä»…æ•°å­—ï¼‰",
        "value": None
    },
    "è¡€å‹èˆ’å¼ å‹": {
        "prompt": "è¯·æä¾›èˆ’å¼ å‹ DBPï¼ˆmmHgï¼Œä»…æ•°å­—ï¼‰",
        "value": None
    },
    "é™æ¯å¿ƒç‡": {
        "prompt": "è¯·æä¾›é™æ¯å¿ƒç‡ HRï¼ˆæ¬¡/åˆ†ï¼Œä»…æ•°å­—ï¼‰",
        "value": None
    },
    "äº²å±ç³–å°¿ç—…ç—…å²": {
        "prompt": "æ‚¨æ˜¯å¦æœ‰ä¸€çº§äº²å±ç³–å°¿ç—…ç—…å²æˆ–è€…å®¶æ—å²ï¼Ÿ",
        "value": None
    },
    "å…¶ä»–é‡è¦è¯´æ˜": {
        "prompt":
            "å¦‚æœæ‚¨æœ‰æ­£åœ¨ä½¿ç”¨çš„è¯ç‰©ã€ç‰¹æ®Šé¥®é£Ÿæˆ–è¿åŠ¨ä¹ æƒ¯ç­‰ï¼Œ"
            "è¿™ä¼šå¸®åŠ©æˆ‘ä»¬æ›´å…¨é¢åœ°äº†è§£æ‚¨çš„å¥åº·çŠ¶å†µã€‚"
            "è¯·æ‚¨è¡¥å……å…¶ä»–é‡è¦è¯´æ˜ï¼š",
        "value": None
    }
}


logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s: %(message)s"
)
logger = logging.getLogger(__name__)
llm = ZhipuLLM()

DATA_DIR = os.path.join(os.path.dirname(__file__), "data")
os.makedirs(DATA_DIR, exist_ok=True)

# CSSï¼šå·¦ä¾§ Ã— å›¾æ ‡ & æ‚¬åœé«˜äº®
css = """
#file-selector .gr-checkbox {
  padding: 8px 8px 8px 28px;
  position: relative;
  border-radius: 4px;
  transition: background-color 0.2s;
}
/* Ã— å›¾æ ‡æ”¾åœ¨å·¦ä¾§ */
#file-selector .gr-checkbox:hover::before {
  content: "Ã—";
  position: absolute;
  left: 8px;
  top: 50%;
  transform: translateY(-50%);
  color: #e00;
  font-size: 16px;
  cursor: pointer;
}
/* æ‚¬åœé«˜äº® */
#file-selector .gr-checkbox:hover {
  background-color: #f5f5f5;
}
/* é™åˆ¶æ¸…é™¤æŒ‰é’®å®½åº¦ */
#clear-btn {
  min-width: 30px;
  max-width: 60px;
}
"""
# æ–°å¢ï¼šçŸ¥è¯†åº“å¢é‡/å¤ç”¨æœºåˆ¶
config = Config.get_instance()
kb_manager = get_zhipu_knowledge_manager()
knowledge_base_path = config.get_with_nested_params("Knowledge-base-path")

# è·å–æˆ–æ›´æ–°çŸ¥è¯†åº“IDï¼ˆå¦‚æœ‰æ–°æ–‡ä»¶åˆ™æ–°å»ºï¼Œå¦åˆ™å¤ç”¨ï¼‰
def get_or_update_knowledge_id():
    # å…ˆæŸ¥æ‰¾æœ¬åœ°å·²å­˜åœ¨çŸ¥è¯†åº“
    knowledge_list = kb_manager.get_knowledge_base_list()
    knowledge_id = None
    if knowledge_list:
        # é»˜è®¤ç”¨ç¬¬ä¸€ä¸ªçŸ¥è¯†åº“
        knowledge_id = knowledge_list[0]["id"]
    # æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ–‡ä»¶éœ€è¦ä¸Šä¼ 
    upload_results = {}
    if knowledge_id:
        upload_results = kb_manager.upload_directory_to_knowledge_base(
            knowledge_id, knowledge_base_path
        )
        # å¦‚æœæœ‰æ–°æ–‡ä»¶ä¸Šä¼ å¤±è´¥ï¼Œæˆ–å…¨éƒ¨å·²å­˜åœ¨ï¼Œåˆ™ç›´æ¥ç”¨æ—§ID
        if any(upload_results.values()):
            return knowledge_id
    # å¦‚æœæ²¡æœ‰çŸ¥è¯†åº“æˆ–å…¨éƒ¨ä¸Šä¼ å¤±è´¥ï¼Œåˆ™æ–°å»º
    if not knowledge_id or not any(upload_results.values()):
        knowledge_id = kb_manager.create_knowledge_base(
            name="ç³–å°¿ç—…æ™ºèƒ½é—®ç­”çŸ¥è¯†åº“",
            description="åŒ…å«ç³–å°¿ç—…ç›¸å…³çŸ¥è¯†ã€æ„å›¾æ£€æµ‹ç­‰å†…å®¹çš„ç»¼åˆçŸ¥è¯†åº“"
        )
        kb_manager.upload_directory_to_knowledge_base(
            knowledge_id, knowledge_base_path
        )
    return knowledge_id

def get_latest_knowledge_id():
    """ä» knowledge_info.json è·å–æœ€æ–°çŸ¥è¯†åº“ID"""
    info_path = os.path.join(DATA_DIR, "knowledge_info.json")
    if not os.path.exists(info_path):
        return None
    with open(info_path, "r", encoding="utf-8") as f:
        info = json.load(f)
    if not info:
        return None
    # å–æœ€åä¸€ä¸ªkeyï¼ˆæœ€æ–°åˆ›å»ºï¼‰
    latest_id = list(info.keys())[-1]
    return latest_id

def on_file_upload(file_paths,chat_history, history, file_list):
    history   = history   or []
    file_list = file_list or []

    # å¦‚æœæ²¡é€‰æ–°æ–‡ä»¶ï¼Œä»…åˆ·æ–°åˆ—è¡¨
    if not file_paths:
        opts = [os.path.basename(p) for p in file_list]
        return history, history, file_list, gr.update(choices=opts, value=[])

    paths = file_paths if isinstance(file_paths, list) else [file_paths]

    from tools.lab_report_parser import parse_lab_report

    for p in paths:
        if p in file_list:
            continue
        file_list.append(p)
        name = os.path.basename(p)
        ext  = os.path.splitext(name)[1].lower().lstrip(".")

        with open(p, "rb") as f:
            file_bytes = f.read()
            b64 = base64.b64encode(file_bytes).decode("utf-8")

        # èŠå¤©åŒºæ’å…¥å›¾ç‰‡/æ–‡ä»¶
        if ext in ("png","jpg","jpeg"):
            md = f"![{name}](data:image/{ext};base64,{b64})"
            history.append({"role":"system", "content":f"å·²ä¸Šä¼ å›¾ç‰‡ï¼š{name}\n\n{md}"})
            # è‡ªåŠ¨è§£æå›¾ç‰‡åŒ»å­¦æŒ‡æ ‡
            result = parse_lab_report(file_bytes)
            print(result)
            # è‡ªåŠ¨éå†æ‰€æœ‰éç©ºåŒ»å­¦æŒ‡æ ‡å¹¶å±•ç¤ºï¼ˆç›´æ¥ç”¨ä¸­æ–‡keyï¼‰
            if any(result.values()):
                summary = []
                for k, v in result.items():
                    if v is not None:
                        summary.append(f"{k}: {v}")
                    if k in INDICATORS and v not in ("", None):
                        INDICATORS[k]["value"] = str(v)
                print(INDICATORS)
                if summary:
                    history.append({"role": "system", "content": "è‡ªåŠ¨è¯†åˆ«ä¿¡æ¯ï¼š\n" + "\n".join(summary)})
        elif ext == "pdf":
            md = f"[ğŸ“„ {name}](data:application/pdf;base64,{b64})"
            history.append({"role":"system","content":f"å·²ä¸Šä¼  PDFï¼š{md}"})
            # è‡ªåŠ¨è§£æ PDF åŒ»å­¦æŒ‡æ ‡
            result = parse_lab_report(file_bytes)
            if any(result.values()):
                summary = []
                for k, v in result.items():
                    if v is not None:
                        summary.append(f"{k}: {v}")
                if summary:
                    history.append({"role": "system", "content": "è‡ªåŠ¨è¯†åˆ«ä¿¡æ¯ï¼š\n" + "\n".join(summary)})
        else:
            history.append({"role":"system","content":f"å·²ä¸Šä¼ æ–‡ä»¶ï¼š{name}"})

    opts = [os.path.basename(p) for p in file_list]
    return history, history, file_list, gr.update(choices=opts, value=[])

def on_delete(selected, file_list):
    # ç‚¹å‡»å‹¾é€‰å³åˆ é™¤
    file_list = file_list or []
    remaining = [p for p in file_list if os.path.basename(p) not in (selected or [])]
    opts = [os.path.basename(p) for p in remaining]
    return remaining, gr.update(choices=opts, value=[])

def on_send(text, file_list, history, name, age, weight, gender, past_history):
    history   = history or []
    user_msg  = text or ""

    if file_list:
        names = ", ".join(os.path.basename(p) for p in file_list)
        suffix = f"[å·²ä¸Šä¼ æ–‡ä»¶ï¼š{names}]"
        user_msg = f"{user_msg}\n{suffix}" if user_msg else suffix
    history.append({"role":"user","content":user_msg})

    missing = [key for key, info in INDICATORS.items() if info["value"] is None]
    print(missing)
    if missing :
        for key, info in INDICATORS.items():
            prompt_text = info["prompt"]
            value = info["value"]
            # æ‰“å°è°ƒè¯•ä¿¡æ¯å¯é€‰
            print(f"æŒ‡æ ‡åï¼š{key}ï¼Œæç¤ºè¯­ï¼š{prompt_text}ï¼Œå·²å¡«å€¼ï¼š{value}")
            if value is None:
                # æŠŠè¿™ä¸ªæŒ‡æ ‡çš„ prompt å‘ç»™ç”¨æˆ·
                history.append({
                    "role": "assistant",
                    "content": prompt_text
                })
                INDICATORS[key]["value"] = user_msg
                return (
                    history,                                     
                    history,                                     
                    file_list,                                    
                    gr.update(choices=[os.path.basename(p) for p in file_list], value=[]), 
                    gr.update(value="")                          
                )

    msg_norm = user_msg.replace("ï¼Œ", ",")
    trigger_rag = (
        "ç³–å°¿ç—…" in msg_norm
        and any(kw in msg_norm for kw in ["é£é™©","æ¦‚ç‡","å¯èƒ½","ä¼šå¾—","æ‚£ç—…","å‡ ç‡","chance","risk","possibility"])
    )
    print(trigger_rag)
    if trigger_rag:
        # 1.1 å®šä¹‰è¦æŠ½å–çš„æŒ‡æ ‡æ­£åˆ™
        indicator_patterns = {
            "å¹´é¾„":           r"(?:å¹´é¾„|age)[^\d]*(\d{1,3})",
            "ç©ºè…¹è¡€ç³–":       r"(?:ç©ºè…¹è¡€ç³–|è¡€ç³–å€¼|è¡€ç³–)[^\d]*(\d+(?:\.\d+)?)",
            "ä¸¤å°æ—¶è¡€ç³–":     r"(?:ä¸¤å°æ—¶è¡€ç³–|2hè¡€ç³–)[^\d]*(\d+(?:\.\d+)?)",
            "ç³–åŒ–è¡€çº¢è›‹ç™½":   r"(?:ç³–åŒ–è¡€çº¢è›‹ç™½|HbA1c)[^\d]*(\d+(?:\.\d+)?)",
            "BMI":           r"(?:BMI|bmi|ä½“è´¨æŒ‡æ•°)[^\d]*(\d+(?:\.\d+)?)",
            "è¡€å‹æ”¶ç¼©å‹":     r"(?:æ”¶ç¼©å‹|SBP)[^\d]*(\d+(?:\.\d+)?)",
            "è¡€å‹èˆ’å¼ å‹":     r"(?:èˆ’å¼ å‹|DBP)[^\d]*(\d+(?:\.\d+)?)",
            "é™æ¯å¿ƒç‡":       r"(?:å¿ƒç‡|é™æ¯å¿ƒç‡|HR)[^\d]*(\d+(?:\.\d+)?)",
        }
        # print(f"indicator_patterns"+{indicator_patterns})
        # 1.2 æŠ½å–å¹¶å¡«å…… INDICATORS
        for k, pat in indicator_patterns.items():
            if INDICATORS.get(k, {}).get("value") in (None, ""):
                m = re.search(pat, user_msg, re.IGNORECASE)
                if m:
                    INDICATORS[k]["value"] = m.group(1)
        # 1.3 èšåˆæ•°å€¼ç‰¹å¾
        auto_features = {}
        for k, info in INDICATORS.items():
            try:
                auto_features[k] = float(info["value"])
            except:
                pass
        # 1.4 è°ƒç”¨ç›¸ä¼¼ç—…ä¾‹æ£€ç´¢
        if auto_features:
            from rag.index_diabetes import generate_scientific_advice
            rag_info = generate_scientific_advice(auto_features)
            print('auto_features:', auto_features)
            print('rag_info:', rag_info if rag_info else 'æœªè§¦å‘rag')
            if rag_info:
                history.append({
                    "role": "system",
                    "content": "ã€æ•°æ®é›†ç›¸ä¼¼ç—…ä¾‹å‚è€ƒã€‘\n" + rag_info
                })
        # 1.5 æ„å»ºå¹¶è°ƒç”¨ RAG Prompt
        personal = f"å§“åï¼š{name or 'æœªå¡«å†™'}ï¼›å¹´é¾„ï¼š{age or 'æœªå¡«å†™'}ï¼›ä½“é‡ï¼š{weight or 'æœªå¡«å†™'}ï¼›æ€§åˆ«ï¼š{gender or 'æœªå¡«å†™'}ï¼›æ—¢å¾€å²ï¼š{past_history or 'æœªå¡«å†™'}"
        prompt_parts = [f"ç”¨æˆ·ä¸ªäººä¿¡æ¯ï¼š{personal}"]
        # å¯é€‰ï¼šè‡ªåŠ¨è¯†åˆ«çš„æŠ¥å‘Šä¿¡æ¯
        for m in reversed(history):
            if m["role"]=="system" and m["content"].startswith("è‡ªåŠ¨è¯†åˆ«ä¿¡æ¯ï¼š"):
                prompt_parts.append(m["content"])
                break
        # åŠ å…¥ç›¸ä¼¼ç—…ä¾‹å‚è€ƒ
        for m in reversed(history):
            if m["role"]=="system" and m["content"].startswith("ã€æ•°æ®é›†ç›¸ä¼¼ç—…ä¾‹å‚è€ƒã€‘"):
                prompt_parts.append(m["content"])
                break     
        
        final_prompt = (
            "è¯·é˜…è¯»ä»¥ä¸‹ 5 ä¸ªå…¸å‹ç›¸ä¼¼ç—…ä¾‹åŠå…¶å…³é”®ç‰¹å¾ï¼š\n"
            "ç›¸ä¼¼ç—…ä¾‹1ï¼šgender:Female, age:0.56, hypertension:0, heart_disease:0, bmi:11.08, "
            "HbA1c_level:3.5, blood_glucose_level:140, diabetes:0\n"
            "ç›¸ä¼¼ç—…ä¾‹2ï¼šgender:Male,   age:0.72, hypertension:0, heart_disease:0, bmi:11.98, "
            "HbA1c_level:5.8, blood_glucose_level:140, diabetes:0\n"
            "ç›¸ä¼¼ç—…ä¾‹3ï¼šgender:Female, age:0.08, hypertension:0, heart_disease:0, bmi:12.74, "
            "HbA1c_level:3.5, blood_glucose_level:140, diabetes:0\n"
            "ç›¸ä¼¼ç—…ä¾‹4ï¼šgender:Female, age:0.56, hypertension:0, heart_disease:0, bmi:12.10, "
            "HbA1c_level:6.0, blood_glucose_level:140, diabetes:0\n"
            "ç›¸ä¼¼ç—…ä¾‹5ï¼šgender:Female, age:0.56, hypertension:0, heart_disease:0, bmi:12.33, "
            "HbA1c_level:5.7, blood_glucose_level:140, diabetes:0\n\n"
            "é£é™©åˆ†çº§è§„åˆ™ï¼š\n"
            "Â Â â€¢ 0â€“1 ä¾‹ï¼šä½é£é™©\n"
            "Â Â â€¢ 2â€“3 ä¾‹ï¼šä¸­é£é™©\n"
            "Â Â â€¢ 4â€“5 ä¾‹ï¼šé«˜é£é™©\n\n"
            f"å½“å‰ç”¨æˆ·ç‰¹å¾ï¼š{auto_features}\n\n"
            "è¯·ä»¥ä¸“ä¸šä¸”é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è¯„ä¼°è¯¥ç”¨æˆ·çš„ç³–å°¿ç—…æ‚£ç—…é£é™©ç­‰çº§ï¼ˆä½/ä¸­/é«˜ï¼‰ï¼Œ"
            "å¹¶ç®€è¦è¯´æ˜æ‚¨çš„å¯¹è¿™äº›æŒ‡æ ‡æ•°æ®çš„åˆ†æåŠç›¸åº”çš„å¥åº·ç®¡ç†å»ºè®®ã€‚"
            "è¯·å‹¿åœ¨å›å¤ä¸­é‡å¤ä¸Šè¿°åˆ†çº§è§„åˆ™åç§°æˆ–å­—æ®µæ ‡ç­¾ï¼Œä¹Ÿæ— éœ€å±•ç¤ºåŸå§‹ç‰¹å¾æ•°æ®ã€‚"
        )

        reply = llm._call(final_prompt)
        history.append({"role": "assistant", "content": reply})

        return history, history, [], gr.update(choices=[], value=[]), gr.update(value="")

    #ç¬¬äºŒç§é˜¶æ®µ
    else:

        # ä»…æ‹¼æ¥å·²ä¸Šä¼ æ–‡ä»¶ä¿¡æ¯
        if file_list:
            names = ", ".join(os.path.basename(p) for p in file_list)
            user_msg = (user_msg + "\n" if user_msg else "") + f"[å·²ä¸Šä¼ æ–‡ä»¶ï¼š{names}]"

        # æ‹¼æ¥ä¸ªäººä¿¡æ¯ï¼ˆåç«¯ä¼ ç»™æ¨¡å‹ï¼Œä¸æ˜¾ç¤ºåœ¨èŠå¤©åŒºï¼‰
        personal_info = (
            f"å§“åï¼š{name or 'æœªå¡«å†™'}ï¼›å¹´é¾„ï¼š{age or 'æœªå¡«å†™'}ï¼›ä½“é‡ï¼š{weight or 'æœªå¡«å†™'}ï¼›"
            f"æ€§åˆ«ï¼š{gender or 'æœªå¡«å†™'}ï¼›æ—¢å¾€å²ï¼š{past_history or 'æœªå¡«å†™'}"
        )

        # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡/æŠ¥å‘Šè‡ªåŠ¨è¯†åˆ«ä¿¡æ¯
        auto_info = None
        for m in reversed(history):
            if m["role"] == "system" and m["content"].startswith("è‡ªåŠ¨è¯†åˆ«ä¿¡æ¯ï¼š"):
                auto_info = m["content"]
                break

        # LLM å»ºè®®
        if auto_info:
            prompt = (
                "è¯·ä½¿ç”¨ä¸­æ–‡å›å¤ã€‚\n"
                f"ç”¨æˆ·åŸºæœ¬ä¿¡æ¯ï¼š{personal_info}\n"
                f"ç³»ç»Ÿè‡ªåŠ¨è¯†åˆ«çš„åŒ»å­¦æŠ¥å‘Š/å›¾ç‰‡ä¿¡æ¯ï¼š\n{auto_info}\n"
                f"ç”¨æˆ·æè¿°ï¼š{user_msg}\n\n"
                "è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼š\n"
                "å¯¹ç”¨æˆ·è¾“å…¥çš„å†…å®¹ï¼ŒåŠæ‰€å…³å¿ƒçš„é—®é¢˜ï¼Œæå‡ºå…³äºç³–å°¿ç—…çš„ä¸“ä¸šåˆ†æã€å»ºè®®"
                "å¦‚æœ‰ç¼ºå¤±å…³é”®ä¿¡æ¯ï¼Œå¯ç®€è¦æé†’ç”¨æˆ·è¡¥å……ï¼Œä½†æ— éœ€è¯´æ˜æ— æ³•è¯†åˆ«å›¾ç‰‡ã€‚"
            )
        else:
            prompt = (
                f"å¿…é¡»ä½¿ç”¨ä¸­æ–‡å›ç­”"
                f"ç”¨æˆ·ä¸ªäººä¿¡æ¯ï¼š{personal_info}\n"
                f"ç”¨æˆ·æ¶ˆæ¯ï¼š{user_msg}\n"
                "è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼š\n"
                "å¯¹ç”¨æˆ·è¾“å…¥çš„å†…å®¹ï¼ŒåŠæ‰€å…³å¿ƒçš„é—®é¢˜ï¼Œæå‡ºå…³äºç³–å°¿ç—…çš„ä¸“ä¸šåˆ†æã€å»ºè®®"
            )
        logger.info("Prompt to LLM: %s", prompt)
        # RAG æ£€ç´¢ï¼šè°ƒç”¨æ™ºæ™®çŸ¥è¯†åº“å¯¹è¯æ¥å£
        kb_id = get_or_update_knowledge_id()
        try:
            kb_reply = kb_manager.chat_with_knowledge_base(
                knowledge_id=kb_id,
                question=user_msg,
                stream=False
            )
        except Exception as e:
            kb_reply = f"çŸ¥è¯†åº“æ£€ç´¢å‡ºé”™ï¼š{e}"

        # æ„å»º Prompt
        prompt_parts = [f"ç”¨æˆ·ä¸ªäººä¿¡æ¯ï¼š{personal_info}"]
        if auto_info:
            prompt_parts.append(f"ç³»ç»Ÿè‡ªåŠ¨è¯†åˆ«ä¿¡æ¯ï¼š\n{auto_info}")
        prompt_parts.append(f"çŸ¥è¯†åº“å›å¤ï¼š\n{kb_reply}")
        prompt_parts.append(f"ç”¨æˆ·æ¶ˆæ¯ï¼š{user_msg}")
        prompt_parts.append("è¯·åŸºäºä¸Šè¿°ä¿¡æ¯ç»™å‡ºä¸“ä¸šã€å‡†ç¡®çš„ç³–å°¿ç—…ç®¡ç†å»ºè®®ã€‚å¿…é¡»ä½¿ç”¨ä¸­æ–‡å›ç­”")
        final_prompt = "\n".join(prompt_parts)
        logger.info("Final RAG Prompt to LLM: %s", final_prompt)

        # è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆæœ€ç»ˆå›å¤
        try:
            reply = llm._call(final_prompt)
        except Exception as e:
            reply = f"æ¨¡å‹è°ƒç”¨å‡ºé”™ï¼š{e}"
        history.append({"role": "assistant", "content": reply})

        # æ¸…ç©ºä¸Šä¼ åˆ—è¡¨
        return (
            history,
            history,
            [],
            gr.update(choices=[], value=[]),
            gr.update(value="")
        )


def on_generate_case(history, name=None, age=None, weight=None, gender=None, past_history=None):
    # åˆ¤æ–­ä¸ªäººä¿¡æ¯æ˜¯å¦å¡«å†™
    info_filled = any([name, age, weight, gender, past_history])
    # åˆ¤æ–­æ˜¯å¦æœ‰å¯¹è¯å†…å®¹ï¼ˆæ’é™¤åˆå§‹æ¬¢è¿è¯­ï¼‰
    dialog_filled = history and any(
        m["role"] == "user" and m["content"].strip() for m in history if m["role"] == "user"
    )

    # æƒ…å†µ1ï¼šä¸ªäººä¿¡æ¯å’Œå¯¹è¯éƒ½æ²¡æœ‰
    if not info_filled and not dialog_filled:
        return "æ²¡æœ‰ä¿¡æ¯å¯ä»¥ç”Ÿæˆç—…ä¾‹æŠ¥å‘Šå•ï¼Œè¯·å…ˆå¡«å†™ä¸ªäººä¿¡æ¯æˆ–è¿›è¡Œå¯¹è¯ã€‚"

    # æƒ…å†µ2ï¼šåªæœ‰ä¸ªäººä¿¡æ¯
    if info_filled and not dialog_filled:
        personal_info = (
            f"å§“åï¼š{name or 'æœªå¡«å†™'}\n"
            f"å¹´é¾„ï¼š{age or 'æœªå¡«å†™'}\n"
            f"ä½“é‡ï¼š{weight or 'æœªå¡«å†™'}\n"
            f"æ€§åˆ«ï¼š{gender or 'æœªå¡«å†™'}\n"
            f"æ—¢å¾€å²ï¼š{past_history or 'æœªå¡«å†™'}"
        )
        return f"**ç—…ä¾‹æŠ¥å‘Šå•**\n\n{personal_info}"

    # æƒ…å†µ3ï¼šåªæœ‰å¯¹è¯å†…å®¹
    if not info_filled and dialog_filled:
        personal_info = (
            f"å§“åï¼šæ— \nå¹´é¾„ï¼šæ— \nä½“é‡ï¼šæ— \næ€§åˆ«ï¼šæ— \næ—¢å¾€å²ï¼šæ— "
        )
        hist = "\n".join(f"{m['role']}: {m['content']}" for m in history)
        case_p = (
            f"è¯·æ ¹æ®ä»¥ä¸‹å¯¹è¯ç”Ÿæˆç»“æ„åŒ–ç³–å°¿ç—…ç—…ä¾‹ï¼š\n\n"
            f"{personal_info}\n\n{hist}\n\n"
            "ç—…ä¾‹åº”åŒ…æ‹¬ï¼šç”¨æˆ·ä¸ªäººä¿¡æ¯(å§“åï¼Œå¹´é¾„ï¼Œä½“é‡ï¼Œæ€§åˆ«)ã€ä¸»è¯‰ã€ç°ç—…å²ã€æ—¢å¾€å²ã€æ£€æŸ¥ç»“æœã€åˆæ­¥è¯Šæ–­ã€ç®¡ç†å»ºè®®ã€‚æ§åˆ¶å­—æ•°åœ¨500å­—ä¹‹å†…"
            "æ³¨æ„åˆæ­¥è¯Šæ–­åº”è¯¥å†™ä¸ºä¹‹å‰å¯¹è¯å†å²æ‰€è®¤ä¸ºçš„æ‚£ç—…é£é™©"
        )
        logger.info("Case prompt to LLM: %s", case_p)
        try:
            case = llm._call(case_p)
        except Exception as e:
            case = f"ç”Ÿæˆç—…ä¾‹å‡ºé”™ï¼š{e}"
            return case
        return case

    # æƒ…å†µ4ï¼šä¸ªäººä¿¡æ¯å’Œå¯¹è¯éƒ½æœ‰
    personal_info = (
        f"å§“åï¼š{name or 'æœªå¡«å†™'}ï¼›å¹´é¾„ï¼š{age or 'æœªå¡«å†™'}ï¼›ä½“é‡ï¼š{weight or 'æœªå¡«å†™'}ï¼›"
        f"æ€§åˆ«ï¼š{gender or 'æœªå¡«å†™'}ï¼›æ—¢å¾€å²ï¼š{past_history or 'æœªå¡«å†™'}"
    )
    hist = "\n".join(f"{m['role']}: {m['content']}" for m in history)
    case_p = (
        f"è¯·æ ¹æ®ä»¥ä¸‹å¯¹è¯å’Œä¸ªäººä¿¡æ¯ç”Ÿæˆç»“æ„åŒ–ç³–å°¿ç—…ç—…ä¾‹ï¼š\n\n"
        f"{personal_info}\n\n{hist}\n\n"
        "ç—…ä¾‹åº”åŒ…æ‹¬ï¼šç”¨æˆ·ä¸ªäººä¿¡æ¯(å§“åï¼Œå¹´é¾„ï¼Œä½“é‡ï¼Œæ€§åˆ«)ã€ä¸»è¯‰ã€ç°ç—…å²ã€æ—¢å¾€å²ã€æ£€æŸ¥ç»“æœã€åˆæ­¥è¯Šæ–­ã€ç®¡ç†å»ºè®®ã€‚æ§åˆ¶å­—æ•°åœ¨500å­—ä¹‹å†…"
    )
    logger.info("Case prompt to LLM: %s", case_p)
    try:
        case = llm._call(case_p)
    except Exception as e:
        case = f"ç”Ÿæˆç—…ä¾‹å‡ºé”™ï¼š{e}"
        return case
    return case

def on_clear_history():
    welcome_msg = [{"role": "assistant", "content": "æ‚¨å¥½ï¼Œæˆ‘æ˜¯ç³–å°¿ç—…ä¸“ä¸šåŠ©æ‰‹ï¼Œè¯·æ‚¨æä¾›è¯¦ç»†ç—…ä¾‹ä¿¡æ¯ï¼Œä»¥ä¾¿æˆ‘ä¸ºæ‚¨é‡èº«å®šåˆ¶åŒ»å­¦å»ºè®®ã€‚ä½ æœ‰å…³äºæœ€è¿‘çš„æŠ¥å‘Šå¯ä»¥ç»™æˆ‘çœ‹çœ‹å—"}]
    return welcome_msg, welcome_msg, "**ç—…ä¾‹è®°å½•**\n\nå°šæ— å†…å®¹"

with gr.Blocks(css=css) as demo:
    gr.Markdown("## ç³–å°¿ç—…åŠ©æ‰‹ ğŸ©¸ â€” å·¦ï¼šå¯¹è¯äº¤äº’ï¼›å³ï¼šç—…ä¾‹è®°å½•")

    # æ–°å¢ï¼šä¸ªäººä¿¡æ¯è¾“å…¥æ¡†
    with gr.Row():
        name_input = gr.Textbox(label="å§“å", placeholder="è¯·è¾“å…¥å§“å", lines=1)
        age_input = gr.Textbox(label="å¹´é¾„", placeholder="è¯·è¾“å…¥å¹´é¾„", lines=1)
        weight_input = gr.Textbox(label="ä½“é‡ï¼ˆkgï¼‰", placeholder="è¯·è¾“å…¥ä½“é‡", lines=1)
        gender_input = gr.Dropdown(label="æ€§åˆ«", choices=["ç”·", "å¥³"], value=None)
        history_input = gr.Textbox(label="æ—¢å¾€å²", placeholder="è¯·è¾“å…¥æ—¢å¾€å²", lines=1)

    # åˆå§‹å¼•å¯¼æ¶ˆæ¯
    initial_messages = [{
        "role": "assistant",
        "content": (
            "æ‚¨å¥½ï¼Œæˆ‘æ˜¯æ‚¨çš„æ™ºèƒ½ç³–å°¿ç—…å¥åº·ç®¡ç†åŠ©æ‰‹ï¼Œå¯ä»¥ä¸ºæ‚¨æä¾›ç³–å°¿ç—…ç›¸å…³çš„æ£€æµ‹è§£è¯»ã€å¥åº·å»ºè®®å’Œä¸ªæ€§åŒ–ç®¡ç†æ–¹æ¡ˆã€‚\n"
            "è¯·é—®æ‚¨æœ€è¿‘æœ‰åšè¿‡ä»€ä¹ˆåŒ»å­¦æŠ¥å‘Šå—ï¼Œæˆ‘ä¼šå…ˆå¯¹æ‚¨åšä¸€ä¸ªç®€å•çš„é—®è¯¢"
        )
    }]

    with gr.Row():
        # å·¦ä¾§å¯¹è¯åŒºåŸŸ
        with gr.Column(scale=3):
            chatbot = gr.Chatbot(type="messages", label="å¯¹è¯è®°å½•", height=500)
            with gr.Row():
                upload_btn = gr.UploadButton(
                    "ğŸ“ ä¸Šä¼ æ–‡ä»¶",
                    file_types=[".png",".jpg",".jpeg",".pdf"],
                    file_count="multiple",
                    type="filepath",
                    elem_id="upload-btn",
                    scale=1
                )
                text_input = gr.Textbox(
                    placeholder="è¯·è¾“å…¥é—®é¢˜æˆ–å¤‡æ³¨ï¼ˆå¯é€‰ï¼‰",
                    lines=1,
                    show_label=False,
                    elem_id="text-input",
                    scale=2
                )
                send_btn = gr.Button("å‘é€", elem_id="send-btn", scale=1)
            file_list = gr.State([])  # ç”¨äºå­˜å‚¨æ–‡ä»¶è·¯å¾„
            file_selector = gr.CheckboxGroup(
                choices=[],
                label="å·²ä¸Šä¼ æ–‡ä»¶ï¼ˆç‚¹å‡» Ã— åˆ é™¤ï¼‰",
                elem_id="file-selector"
            )
            with gr.Row():
                gr.Examples(
                    examples=[
                        "ç³–å°¿ç—…å¦‚ä½•æ§åˆ¶è¡€ç³–ï¼Ÿ",
                        "èƒ°å²›ç´ ä½¿ç”¨æ³¨æ„äº‹é¡¹ï¼Ÿ",
                        "ä½è¡€ç³–å¤„ç†æ–¹å¼",
                        "æˆ‘æœ€è¿‘è¡€ç³–æœ‰ç‚¹é«˜ï¼Œæ€ä¹ˆç¼“è§£ï¼Ÿ",
                        "ç³–å°¿ç—…é¥®é£Ÿæœ‰å“ªäº›ç¦å¿Œï¼Ÿ",
                        "è¿åŠ¨å¯¹è¡€ç³–å½±å“",
                        "å¦‚ä½•ç›‘æµ‹è¡€ç³–å˜åŒ–ï¼Ÿ",
                        "ç³–å°¿ç—…å¹¶å‘ç—‡æœ‰å“ªäº›ï¼Ÿ",
                        "èƒ°å²›ç´ æ³µçš„é€‚ç”¨æ€§",
                        "è¡€ç³–é«˜æœ‰å“ªäº›ç—‡çŠ¶ï¼Ÿ",
                    ],
                    inputs=[text_input]
                )
                clear_btn = gr.Button("æ¸…é™¤å¯¹è¯å†å²", elem_id="clear-btn", scale=1)

        # å³ä¾§ç—…ä¾‹è®°å½•
        with gr.Column(scale=2):
            case_md = gr.Markdown("**ç—…ä¾‹è®°å½•**\n\nå°šæ— å†…å®¹")
            gen_case_btn = gr.Button("ç”Ÿæˆç—…ä¾‹æŠ¥å‘Šå•", elem_id="gen-case-btn")

    state = gr.State(initial_messages)

    # ä¸Šä¼  -> æ›´æ–°èŠå¤© & æ–‡ä»¶åˆ—è¡¨
    upload_btn.upload(
        fn=on_file_upload,
        inputs=[upload_btn,chatbot, state, file_list],
        outputs=[chatbot, state, file_list, file_selector]
    )
    # å‹¾é€‰å³åˆ é™¤
    file_selector.change(
        fn=on_delete,
        inputs=[file_selector, file_list],
        outputs=[file_list, file_selector]
    )
    # å‘é€ -> ç”Ÿæˆå›å¤ï¼Œå¹¶æ¸…ç©ºæ–‡ä»¶åˆ—è¡¨å’Œè¾“å…¥æ¡†
    send_btn.click(
        fn=on_send,
        inputs=[text_input, file_list, state, name_input, age_input, weight_input, gender_input, history_input],
        outputs=[chatbot, state, file_list, file_selector, text_input]
    )
    text_input.submit(
        fn=on_send,
        inputs=[text_input, file_list, state, name_input, age_input, weight_input, gender_input, history_input],
        outputs=[chatbot, state, file_list, file_selector, text_input]
    )
    # æ¸…é™¤å¯¹è¯å†å²æŒ‰é’®
    clear_btn.click(
        fn=on_clear_history,
        inputs=None,
        outputs=[chatbot, state, case_md]
    )
    # ç”Ÿæˆç—…ä¾‹æŠ¥å‘Šå•æŒ‰é’®
    gen_case_btn.click(
        fn=on_generate_case,
        inputs=[state, name_input, age_input, weight_input, gender_input, history_input],
        outputs=[case_md]
    )
    demo.load(
        fn=lambda: (initial_messages, initial_messages),
        inputs=None,
        outputs=[chatbot, state]
    )
if __name__ == "__main__":
    demo.launch(inbrowser=True)
