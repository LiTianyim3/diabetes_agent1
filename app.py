import os,re
import base64
import logging
import gradio as gr
from client.zhipu_llm import ZhipuLLM
import datetime
from rag.zhipu_knowledge_manager import get_zhipu_knowledge_manager
from config.config import Config
import json
from tools.case_json_manager import save_case_json
from ui.custom_ui import build_ui  # æ–°å¢ï¼šå¯¼å…¥è‡ªå®šä¹‰UI

KEY_MAP = {
    "ç©ºè…¹è¡€ç³–":       "ç©ºè…¹è¡€ç³–(GLUO)",
    "åŠå°æ—¶è¡€ç³–":     "åŠå°æ—¶è¡€ç³–(GLU0.5)",   # å¦‚æœè§£æå™¨è¾“å‡ºâ€œåŠå°æ—¶è¡€ç³–â€æƒ³å¡«åˆ°â€œäºŒå°æ—¶è¡€ç³–(GLU2)â€é‡Œï¼Œè¯·æŒ‰éœ€è°ƒæ•´
    "ä¸€å°æ—¶è¡€ç³–":     "ä¸€å°æ—¶è¡€ç³–(GLU1)",
    "ä¸¤å°æ—¶è¡€ç³–":     "ä¸¤å°æ—¶è¡€ç³–(GLU2)",
    "ä¸‰å°æ—¶è¡€ç³–":     "ä¸‰å°æ—¶è¡€ç³–(GLU3)",
    "ç³–åŒ–è¡€çº¢è›‹ç™½":   "ç³–åŒ–è¡€çº¢è›‹ç™½(HbA1C)",
    "ç©ºè…¹è¡€ç³–(GLUO)": "ç©ºè…¹è¡€ç³–",
    "åŠå°æ—¶è¡€ç³–(GLUO0.5)":     "åŠå°æ—¶è¡€ç³–",   # å¦‚æœè§£æå™¨è¾“å‡ºâ€œåŠå°æ—¶è¡€ç³–â€æƒ³å¡«åˆ°â€œäºŒå°æ—¶è¡€ç³–(GLU2)â€é‡Œï¼Œè¯·æŒ‰éœ€è°ƒæ•´
    "ä¸€å°æ—¶è¡€ç³–(GLU1)":     "ä¸€å°æ—¶è¡€ç³–",
    "ä¸¤å°æ—¶è¡€ç³–(GLU2)":     "ä¸¤å°æ—¶è¡€ç³–",
    "ä¸‰å°æ—¶è¡€ç³–(GLU3)":     "ä¸‰å°æ—¶è¡€ç³–",
    "ç³–åŒ–è¡€çº¢è›‹ç™½(HbA1C)":   "ç³–åŒ–è¡€çº¢è›‹ç™½",
    "BMI":           "BMI",
    "èº«é«˜":           None,  # ä¸éœ€è¦æç¤ºæ—¶å¯è®¾ä¸º None
    "ä½“é‡":           None,
    "æ”¶ç¼©å‹":         "è¡€å‹æ”¶ç¼©å‹",
    "èˆ’å¼ å‹":         "è¡€å‹èˆ’å¼ å‹",
    "å¿ƒç‡":           "é™æ¯å¿ƒç‡",
    "ä½“æ¸©":           "ä½“æ¸©",
    # â€¦â€¦å¦‚æœ‰å…¶å®ƒå­—æ®µï¼ŒæŒ‰å®é™…è¡¥å……
}

INDICATORS = {
    "å¹´é¾„": {
        "prompt":
            "æˆ‘å·²ç»çœ‹åˆ°äº†æŠ¥å‘Šæ¥ä¸‹æ¥æˆ‘ä¼šé—®å‡ ä¸ªé—®é¢˜"
            "æ‚¨å¤šå¤§äº†",
        "value": None
    },
    "ç—‡çŠ¶": {
        "prompt":
            "ä¸ºäº†æ›´å¥½åœ°äº†è§£æ‚¨çš„æƒ…å†µï¼Œ"
            "è¯·æ‚¨å›æƒ³æœ€è¿‘æ˜¯å¦å‡ºç°ä»¥ä¸‹ç—‡çŠ¶â€”â€”"
            "å¦‚å£æ¸´ã€æ’å°¿å¢å¤šæˆ–é£Ÿé‡æ˜æ˜¾å¢åŠ ï¼Ÿ",
        "value": None
    },
    "ç©ºè…¹è¡€ç³–(GLU0)": {
        "prompt":
            "æ¸…æ™¨ç©ºè…¹æ—¶ï¼ˆæœªè¿›é£Ÿè‡³å°‘8å°æ—¶ï¼‰ï¼Œ"
            "æ‚¨çš„è¡€ç³–å¤§çº¦æ˜¯å¤šå°‘ï¼Ÿ"
            "è¯·ç›´æ¥è¾“å…¥æ•°å€¼ï¼ˆmmol/Lï¼‰ã€‚",
        "value": None
    },
    "äºŒå°æ—¶è¡€ç³–(GLU2)": {
        "prompt": "åœ¨è¿›é¤åä¸¤å°æ—¶å†…æµ‹å¾—çš„è¡€ç³–å€¼æ˜¯å¤šå°‘ï¼Ÿ",
        "value": None
    },
    "ç³–åŒ–è¡€çº¢è›‹ç™½(HbA1c)": {
        "prompt": "æœ€è¿‘ä¸€æ¬¡ç³–åŒ–è¡€çº¢è›‹ç™½ï¼ˆHbA1cï¼‰æ£€æµ‹ç»“æœæ˜¯å¤šå°‘ï¼Ÿ",
        "value": None
    },
    "BMI": {
        "prompt":
            "BMIï¼ˆä½“è´¨æŒ‡æ•°ï¼‰ç”¨äºè¯„ä¼°ä½“é‡æ˜¯å¦åœ¨å¥åº·èŒƒå›´ï¼Œ"
            "ä¸ç³–å°¿ç—…é£é™©å¯†åˆ‡ç›¸å…³ã€‚"
            "è¯·æ‚¨å‘Šè¯‰æˆ‘æ‚¨çš„ BMI å€¼ï¼ˆkg/mÂ²ï¼Œä»…æ•°å­—ï¼‰ï¼Œ",
        "value": None
    },
    "è¡€å‹æ”¶ç¼©å‹": {
        "prompt": "è¯·æä¾›æ”¶ç¼©å‹ SBPï¼ˆmmHgï¼Œä»…æ•°å­—ï¼‰",
        "value": None
    },
    "è¡€å‹èˆ’å¼ å‹": {
        "prompt": "è¯·æä¾›èˆ’å¼ å‹ DBPï¼ˆmmHgï¼Œä»…æ•°å­—ï¼‰",
        "value": None
    },
    "é™æ¯å¿ƒç‡": {
        "prompt": "è¯·æä¾›é™æ¯å¿ƒç‡ HRï¼ˆæ¬¡/åˆ†ï¼Œä»…æ•°å­—ï¼‰",
        "value": None
    },
    "äº²å±ç³–å°¿ç—…ç—…å²": {
        "prompt": "æ‚¨æ˜¯å¦æœ‰ä¸€çº§äº²å±ç³–å°¿ç—…ç—…å²æˆ–è€…å®¶æ—å²ï¼Ÿ",
        "value": None
    },
    "å…¶ä»–é‡è¦è¯´æ˜": {
        "prompt":
            "å¦‚æœæ‚¨æœ‰æ­£åœ¨ä½¿ç”¨çš„è¯ç‰©ã€ç‰¹æ®Šé¥®é£Ÿæˆ–è¿åŠ¨ä¹ æƒ¯ç­‰ï¼Œ"
            "è¿™ä¼šå¸®åŠ©æˆ‘ä»¬æ›´å…¨é¢åœ°äº†è§£æ‚¨çš„å¥åº·çŠ¶å†µã€‚"
            "è¯·æ‚¨è¡¥å……å…¶ä»–é‡è¦è¯´æ˜ï¼š",
        "value": None
    }
}


logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s: %(message)s"
)
logger = logging.getLogger(__name__)
llm = ZhipuLLM()

DATA_DIR = os.path.join(os.path.dirname(__file__), "data")
os.makedirs(DATA_DIR, exist_ok=True)

# CSSï¼šå·¦ä¾§ Ã— å›¾æ ‡ & æ‚¬åœé«˜äº®
css = """
#file-selector .gr-checkbox {
  padding: 8px 8px 8px 28px;
  position: relative;
  border-radius: 4px;
  transition: background-color 0.2s;
}
/* Ã— å›¾æ ‡æ”¾åœ¨å·¦ä¾§ */
#file-selector .gr-checkbox:hover::before {
  content: "Ã—";
  position: absolute;
  left: 8px;
  top: 50%;
  transform: translateY(-50%);
  color: #e00;
  font-size: 16px;
  cursor: pointer;
}
/* æ‚¬åœé«˜äº® */
#file-selector .gr-checkbox:hover {
  background-color: #f5f5f5;
}
/* é™åˆ¶æ¸…é™¤æŒ‰é’®å®½åº¦ */
#clear-btn {
  min-width: 30px;
  max-width: 60px;
}
"""
def image_to_base64(image_path):
    """å°†å›¾ç‰‡æ–‡ä»¶è½¬æ¢ä¸ºbase64ç¼–ç å­—ç¬¦ä¸²"""
    with open(image_path, "rb") as image_file:
        encoded_string = base64.b64encode(image_file.read()).decode("utf-8")
        return encoded_string

# æ–°å¢ï¼šçŸ¥è¯†åº“å¢é‡/å¤ç”¨æœºåˆ¶
config = Config.get_instance()
kb_manager = get_zhipu_knowledge_manager()
knowledge_base_path = config.get_with_nested_params("Knowledge-base-path")

# è·å–æˆ–æ›´æ–°çŸ¥è¯†åº“IDï¼ˆå¦‚æœ‰æ–°æ–‡ä»¶åˆ™æ–°å»ºï¼Œå¦åˆ™å¤ç”¨ï¼‰
def get_or_update_knowledge_id():
    # å…ˆæŸ¥æ‰¾æœ¬åœ°å·²å­˜åœ¨çŸ¥è¯†åº“
    knowledge_list = kb_manager.get_knowledge_base_list()
    knowledge_id = None
    if knowledge_list:
        # é»˜è®¤ç”¨ç¬¬ä¸€ä¸ªçŸ¥è¯†åº“
        knowledge_id = knowledge_list[0]["id"]
    # æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ–‡ä»¶éœ€è¦ä¸Šä¼ 
    upload_results = {}
    if knowledge_id:
        upload_results = kb_manager.upload_directory_to_knowledge_base(
            knowledge_id, knowledge_base_path
        )
        # å¦‚æœæœ‰æ–°æ–‡ä»¶ä¸Šä¼ å¤±è´¥ï¼Œæˆ–å…¨éƒ¨å·²å­˜åœ¨ï¼Œåˆ™ç›´æ¥ç”¨æ—§ID
        if any(upload_results.values()):
            return knowledge_id
    # å¦‚æœæ²¡æœ‰çŸ¥è¯†åº“æˆ–å…¨éƒ¨ä¸Šä¼ å¤±è´¥ï¼Œåˆ™æ–°å»º
    if not knowledge_id or not any(upload_results.values()):
        knowledge_id = kb_manager.create_knowledge_base(
            name="ç³–å°¿ç—…æ™ºèƒ½é—®ç­”çŸ¥è¯†åº“",
            description="åŒ…å«ç³–å°¿ç—…ç›¸å…³çŸ¥è¯†ã€æ„å›¾æ£€æµ‹ç­‰å†…å®¹çš„ç»¼åˆçŸ¥è¯†åº“"
        )
        kb_manager.upload_directory_to_knowledge_base(
            knowledge_id, knowledge_base_path
        )
    return knowledge_id

def get_latest_knowledge_id():
    """ä» knowledge_info.json è·å–æœ€æ–°çŸ¥è¯†åº“ID"""
    info_path = os.path.join(DATA_DIR, "knowledge_info.json")
    if not os.path.exists(info_path):
        return None
    with open(info_path, "r", encoding="utf-8") as f:
        info = json.load(f)
    if not info:
        return None
    # å–æœ€åä¸€ä¸ªkeyï¼ˆæœ€æ–°åˆ›å»ºï¼‰
    latest_id = list(info.keys())[-1]
    return latest_id

def on_file_upload(file_paths,chat_history, history, file_list):
    history   = history   or []
    file_list = file_list or []

    # å¦‚æœæ²¡é€‰æ–°æ–‡ä»¶ï¼Œä»…åˆ·æ–°åˆ—è¡¨
    if not file_paths:
        opts = [os.path.basename(p) for p in file_list]
        return history, history, file_list, gr.update(choices=opts, value=[])

    paths = file_paths if isinstance(file_paths, list) else [file_paths]

    from tools.lab_report_parser import parse_lab_report

    for p in paths:
        if p in file_list:
            continue
        file_list.append(p)
        name = os.path.basename(p)
        ext  = os.path.splitext(name)[1].lower().lstrip(".")

        with open(p, "rb") as f:
            file_bytes = f.read()
            b64 = base64.b64encode(file_bytes).decode("utf-8")

        # èŠå¤©åŒºæ’å…¥å›¾ç‰‡/æ–‡ä»¶
        if ext in ("png","jpg","jpeg"):
            # æ„å»ºå›¾ç‰‡æ˜¾ç¤ºHTML
            image_html = f"""
                <div>
                    <img src="data:image/{ext};base64,{b64}" alt="{name}" style="max-width: 100%; height: auto; cursor: pointer; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1);" />
                </div>
            """
            history.append({"role":"system", "content":f"å·²ä¸Šä¼ å›¾ç‰‡ï¼š{name}\n\n{image_html}"})
            # è‡ªåŠ¨è§£æå›¾ç‰‡åŒ»å­¦æŒ‡æ ‡
            result = parse_lab_report(file_bytes)
            print(result)
            # è‡ªåŠ¨éå†æ‰€æœ‰éç©ºåŒ»å­¦æŒ‡æ ‡å¹¶å±•ç¤ºï¼ˆç›´æ¥ç”¨ä¸­æ–‡keyï¼‰
            if any(result.values()):
                summary = []
                for k, v in result.items():
                    if v is not None:
                        summary.append(f"{k}: {v}")
                    if k in INDICATORS and v not in ("", None):
                        INDICATORS[k]["value"] = str(v)
                print(INDICATORS)
                if summary:
                    history.append({"role": "system", "content": "è‡ªåŠ¨è¯†åˆ«ä¿¡æ¯ï¼š\n" + "\n".join(summary)})
        elif ext == "pdf":
            md = f"[ğŸ“„ {name}](data:application/pdf;base64,{b64})"
            history.append({"role":"system","content":f"å·²ä¸Šä¼  PDFï¼š{md}"})
            # è‡ªåŠ¨è§£æ PDF åŒ»å­¦æŒ‡æ ‡
            result = parse_lab_report(file_bytes)
            if any(result.values()):
                summary = []
                for k, v in result.items():
                    if v is not None:
                        summary.append(f"{k}: {v}")
                if summary:
                    history.append({"role": "system", "content": "è‡ªåŠ¨è¯†åˆ«ä¿¡æ¯ï¼š\n" + "\n".join(summary)})
        else:
            history.append({"role":"system","content":f"å·²ä¸Šä¼ æ–‡ä»¶ï¼š{name}"})

    opts = [os.path.basename(p) for p in file_list]
    return history, history, file_list, gr.update(choices=opts, value=[])

def on_delete(selected, file_list):
    # ç‚¹å‡»å‹¾é€‰å³åˆ é™¤
    file_list = file_list or []
    remaining = [p for p in file_list if os.path.basename(p) not in (selected or [])]
    opts = [os.path.basename(p) for p in remaining]
    return remaining, gr.update(choices=opts, value=[])

def on_send(text, file_list, history, name, age, weight, gender, past_history):
    history   = history or []
    user_msg  = text or ""
    # ======================== æ–°å¢ï¼šæ–‡ä»¶æ˜¾ç¤ºä¸ LLM æ¶ˆæ¯åˆ†ç¦» ========================
    # display_msg -> å‘åˆ°èŠå¤©çª—å£ï¼ˆå«å›¾ç‰‡HTMLé¢„è§ˆï¼‰
    # prompt_msg  -> å‘ç»™ LLMï¼ˆåªå¸¦æ–‡ä»¶åï¼Œä¸å¸¦base64ï¼‰
    display_msg = user_msg
    prompt_msg  = user_msg


    if file_list:
        file_display_parts = []  # HTMLç‰‡æ®µåˆ—è¡¨ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
        file_names = []          # æ–‡ä»¶ååˆ—è¡¨ï¼ˆå‘ç»™LLMï¼‰

        for file_path in file_list:
            file_name = os.path.basename(file_path)
            ext = os.path.splitext(file_name)[1].lower().lstrip(".")
            file_names.append(file_name)

            if ext in ("png", "jpg", "jpeg"):
                try:
                    with open(file_path, "rb") as f:
                        file_bytes = f.read()
                    b64 = base64.b64encode(file_bytes).decode("utf-8")
                    # æ³¨æ„ï¼šgr.Chatbot æ”¯æŒ Markdownï¼›æˆ‘ä»¬æ’ HTML <img>ï¼ŒGradio ä¼šåŸæ ·æ¸²æŸ“ï¼ˆæˆ–é™çº§ä¸ºæ–‡æœ¬ï¼‰
                    # å¦‚é‡å®‰å…¨ç­–ç•¥å¯æ”¹ä¸º Markdown ![](...) å†…åµŒ data URIã€‚
                    image_html = (
                        f'<div style="margin:10px 0;">'
                        f'<img src="data:image/{ext};base64,{b64}" alt="{file_name}" '
                        f'style="max-width:100%;height:auto;cursor:pointer;border-radius:8px;'
                        f'box-shadow:0 2px 8px rgba(0,0,0,0.1);" />'
                        f'</div>'
                    )
                    file_display_parts.append(image_html)
                except Exception as e:
                    file_display_parts.append(f"<p>å›¾ç‰‡åŠ è½½å¤±è´¥ï¼š{file_name} - {e}</p>")
            else:
                file_display_parts.append(f"<p>å·²ä¸Šä¼ æ–‡ä»¶ï¼š{file_name}</p>")

        # æŠŠæ‰€æœ‰å›¾ç‰‡/æ–‡ä»¶ HTML æ’åˆ°æ˜¾ç¤ºæ¶ˆæ¯ä¸­
        if file_display_parts:
            file_content = "\n".join(file_display_parts)
            if display_msg:
                display_msg = f"{display_msg}\n\n{file_content}"
            else:
                display_msg = file_content

        # ç»™ LLM çš„æç¤ºï¼šåªå¸¦æ–‡ä»¶ååˆ—è¡¨ï¼Œé¿å…å·¨å‹ base64
        if file_names:
            file_names_str = ", ".join(file_names)
            suffix = f"[å·²ä¸Šä¼ æ–‡ä»¶ï¼š{file_names_str}]"
            prompt_msg = f"{prompt_msg}\n{suffix}" if prompt_msg else suffix

    # æŠŠæ˜¾ç¤ºç”¨æ¶ˆæ¯å†™å…¥å†å²ï¼ˆç”¨æˆ·çœ‹åˆ°çš„ï¼‰
    history.append({"role": "user", "content": display_msg})

    # åç»­é€»è¾‘ä¸€å¾‹ä½¿ç”¨ç²¾ç®€ç‰ˆï¼ˆä¸å«base64ï¼‰çš„ user_msg
    user_msg = prompt_msg
    
    missing = [key for key, info in INDICATORS.items() if info["value"] is None]
    print(missing)
    if missing :
        for key, info in INDICATORS.items():
            prompt_text = info["prompt"]
            value = info["value"]
            # æ‰“å°è°ƒè¯•ä¿¡æ¯å¯é€‰
            print(f"æŒ‡æ ‡åï¼š{key}ï¼Œæç¤ºè¯­ï¼š{prompt_text}ï¼Œå·²å¡«å€¼ï¼š{value}")
            if value is None:
                # æŠŠè¿™ä¸ªæŒ‡æ ‡çš„ prompt å‘ç»™ç”¨æˆ·
                history.append({
                    "role": "assistant",
                    "content": prompt_text
                })
                INDICATORS[key]["value"] = user_msg
                return (
                    history,                                     
                    history,                                     
                    file_list,                                    
                    gr.update(choices=[os.path.basename(p) for p in file_list], value=[]), 
                    gr.update(value="")                          
                )

    msg_norm = user_msg.replace("ï¼Œ", ",")
    trigger_rag = (
        "ç³–å°¿ç—…" in msg_norm
        and any(kw in msg_norm for kw in ["é£é™©","æ¦‚ç‡","å¯èƒ½","ä¼šå¾—","æ‚£ç—…","å‡ ç‡","chance","risk","possibility"])
    )
    print(trigger_rag)
    if trigger_rag:
        # 1.1 å®šä¹‰è¦æŠ½å–çš„æŒ‡æ ‡æ­£åˆ™
        indicator_patterns = {
            "å¹´é¾„":           r"(?:å¹´é¾„|age)[^\d]*(\d{1,3})",
            "ç©ºè…¹è¡€ç³–":       r"(?:ç©ºè…¹è¡€ç³–|è¡€ç³–å€¼|è¡€ç³–)[^\d]*(\d+(?:\.\d+)?)",
            "ä¸¤å°æ—¶è¡€ç³–":     r"(?:ä¸¤å°æ—¶è¡€ç³–|2hè¡€ç³–)[^\d]*(\d+(?:\.\d+)?)",
            "ç³–åŒ–è¡€çº¢è›‹ç™½":   r"(?:ç³–åŒ–è¡€çº¢è›‹ç™½|HbA1c)[^\d]*(\d+(?:\.\d+)?)",
            "BMI":           r"(?:BMI|bmi|ä½“è´¨æŒ‡æ•°)[^\d]*(\d+(?:\.\d+)?)",
            "è¡€å‹æ”¶ç¼©å‹":     r"(?:æ”¶ç¼©å‹|SBP)[^\d]*(\d+(?:\.\d+)?)",
            "è¡€å‹èˆ’å¼ å‹":     r"(?:èˆ’å¼ å‹|DBP)[^\d]*(\d+(?:\.\d+)?)",
            "é™æ¯å¿ƒç‡":       r"(?:å¿ƒç‡|é™æ¯å¿ƒç‡|HR)[^\d]*(\d+(?:\.\d+)?)",
        }
        # print(f"indicator_patterns"+{indicator_patterns})
        # 1.2 æŠ½å–å¹¶å¡«å…… INDICATORS
        for k, pat in indicator_patterns.items():
            if INDICATORS.get(k, {}).get("value") in (None, ""):
                m = re.search(pat, user_msg, re.IGNORECASE)
                if m:
                    INDICATORS[k]["value"] = m.group(1)
        # 1.3 èšåˆæ•°å€¼ç‰¹å¾
        auto_features = {}
        for k, info in INDICATORS.items():
            try:
                auto_features[k] = float(info["value"])
            except:
                pass
        # 1.4 è°ƒç”¨ç›¸ä¼¼ç—…ä¾‹æ£€ç´¢
        if auto_features:
            from rag.test import generate_scientific_advice
            rag_info = generate_scientific_advice(auto_features)
            print('auto_features:', auto_features)
            print('rag_info:', rag_info if rag_info else 'æœªè§¦å‘rag')
            if rag_info:
                history.append({
                    "role": "system",
                    "content": "ã€æ•°æ®é›†ç›¸ä¼¼ç—…ä¾‹å‚è€ƒã€‘\n" + rag_info
                })
        # 1.5 æ„å»ºå¹¶è°ƒç”¨ RAG Prompt
        personal = f"å§“åï¼š{name or 'æœªå¡«å†™'}ï¼›å¹´é¾„ï¼š{age or 'æœªå¡«å†™'}ï¼›ä½“é‡ï¼š{weight or 'æœªå¡«å†™'}ï¼›æ€§åˆ«ï¼š{gender or 'æœªå¡«å†™'}ï¼›æ—¢å¾€å²ï¼š{past_history or 'æœªå¡«å†™'}"
        prompt_parts = [f"ç”¨æˆ·ä¸ªäººä¿¡æ¯ï¼š{personal}"]
        # å¯é€‰ï¼šè‡ªåŠ¨è¯†åˆ«çš„æŠ¥å‘Šä¿¡æ¯
        for m in reversed(history):
            if m["role"]=="system" and m["content"].startswith("è‡ªåŠ¨è¯†åˆ«ä¿¡æ¯ï¼š"):
                prompt_parts.append(m["content"])
                break
        # åŠ å…¥ç›¸ä¼¼ç—…ä¾‹å‚è€ƒ
        for m in reversed(history):
            if m["role"]=="system" and m["content"].startswith("ã€æ•°æ®é›†ç›¸ä¼¼ç—…ä¾‹å‚è€ƒã€‘"):
                prompt_parts.append(m["content"])
                break     

        # ä¿®æ”¹åçš„æç¤ºè¯­
        final_prompt = (
            "è¯·æ ¹æ®ç”¨æˆ·çš„åŒ»å­¦ç‰¹å¾å’Œä¸‹æ–¹çš„ç›¸ä¼¼ç—…ä¾‹ç»Ÿè®¡ç»“æœï¼Œç»¼åˆåˆ†æè¯¥ç”¨æˆ·çš„ç³–å°¿ç—…æ‚£ç—…é£é™©ã€‚\n"
            f"å½“å‰ç”¨æˆ·ç‰¹å¾ï¼š{auto_features}\n"
            f"{rag_info}\n"
            "è¯·åœ¨åˆ†æä¾æ®éƒ¨åˆ†æ˜ç¡®å†™å‡ºï¼šç›¸ä¼¼ç—…ä¾‹ä¸­ï¼Œç³–å°¿ç—…ç—…ä¾‹å æ¯”ä¸ºå¤šå°‘%ï¼Œéç³–å°¿ç—…ç—…ä¾‹å æ¯”ä¸ºå¤šå°‘%ï¼Œå¹¶ç»“åˆç”¨æˆ·çš„è¡€ç³–æŒ‡æ ‡å¼‚å¸¸æƒ…å†µè¿›è¡Œè¯Šæ–­ã€‚\n"
            "è¯·ç”¨ä¸“ä¸šä¸”é€šä¿—æ˜“æ‡‚çš„è¯­è¨€ç»™å‡ºè¯Šæ–­ç»“è®ºï¼Œå¹¶ç®€è¦è¯´æ˜æ‚¨çš„åˆ†æä¾æ®å’Œå¥åº·ç®¡ç†å»ºè®®ã€‚\n"
            "æ— éœ€é‡å¤åˆ†çº§è§„åˆ™æˆ–å­—æ®µæ ‡ç­¾ï¼Œä¹Ÿæ— éœ€å±•ç¤ºåŸå§‹ç‰¹å¾æ•°æ®ã€‚"
        )

        reply = llm._call(final_prompt)
        history.append({"role": "assistant", "content": reply})

        return history, history, [], gr.update(choices=[], value=[]), gr.update(value="")

    #ç¬¬äºŒç§é˜¶æ®µ
    else:

        # ä»…æ‹¼æ¥å·²ä¸Šä¼ æ–‡ä»¶ä¿¡æ¯
        if file_list:
            names = ", ".join(os.path.basename(p) for p in file_list)
            user_msg = (user_msg + "\n" if user_msg else "") + f"[å·²ä¸Šä¼ æ–‡ä»¶ï¼š{names}]"

        # æ‹¼æ¥ä¸ªäººä¿¡æ¯ï¼ˆåç«¯ä¼ ç»™æ¨¡å‹ï¼Œä¸æ˜¾ç¤ºåœ¨èŠå¤©åŒºï¼‰
        personal_info = (
            f"å§“åï¼š{name or 'æœªå¡«å†™'}ï¼›å¹´é¾„ï¼š{age or 'æœªå¡«å†™'}ï¼›ä½“é‡ï¼š{weight or 'æœªå¡«å†™'}ï¼›"
            f"æ€§åˆ«ï¼š{gender or 'æœªå¡«å†™'}ï¼›æ—¢å¾€å²ï¼š{past_history or 'æœªå¡«å†™'}"
        )

        # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡/æŠ¥å‘Šè‡ªåŠ¨è¯†åˆ«ä¿¡æ¯
        auto_info = None
        for m in reversed(history):
            if m["role"] == "system" and m["content"].startswith("è‡ªåŠ¨è¯†åˆ«ä¿¡æ¯ï¼š"):
                auto_info = m["content"]
                break

        # LLM å»ºè®®
        if auto_info:
            prompt = (
                "è¯·ä½¿ç”¨ä¸­æ–‡å›å¤ã€‚\n"
                f"ç”¨æˆ·åŸºæœ¬ä¿¡æ¯ï¼š{personal_info}\n"
                f"ç³»ç»Ÿè‡ªåŠ¨è¯†åˆ«çš„åŒ»å­¦æŠ¥å‘Š/å›¾ç‰‡ä¿¡æ¯ï¼š\n{auto_info}\n"
                f"ç”¨æˆ·æè¿°ï¼š{user_msg}\n\n"
                "è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼š\n"
                "å¯¹ç”¨æˆ·è¾“å…¥çš„å†…å®¹ï¼ŒåŠæ‰€å…³å¿ƒçš„é—®é¢˜ï¼Œæå‡ºå…³äºç³–å°¿ç—…çš„ä¸“ä¸šåˆ†æã€å»ºè®®"
                "å¦‚æœ‰ç¼ºå¤±å…³é”®ä¿¡æ¯ï¼Œå¯ç®€è¦æé†’ç”¨æˆ·è¡¥å……ï¼Œä½†æ— éœ€è¯´æ˜æ— æ³•è¯†åˆ«å›¾ç‰‡ã€‚"
            )
        else:
            prompt = (
                f"å¿…é¡»ä½¿ç”¨ä¸­æ–‡å›ç­”"
                f"ç”¨æˆ·ä¸ªäººä¿¡æ¯ï¼š{personal_info}\n"
                f"ç”¨æˆ·æ¶ˆæ¯ï¼š{user_msg}\n"
                "è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼š\n"
                "å¯¹ç”¨æˆ·è¾“å…¥çš„å†…å®¹ï¼ŒåŠæ‰€å…³å¿ƒçš„é—®é¢˜ï¼Œæå‡ºå…³äºç³–å°¿ç—…çš„ä¸“ä¸šåˆ†æã€å»ºè®®"
            )
        logger.info("Prompt to LLM: %s", prompt)
        # RAG æ£€ç´¢ï¼šè°ƒç”¨æ™ºæ™®çŸ¥è¯†åº“å¯¹è¯æ¥å£
        kb_id = get_or_update_knowledge_id()
        try:
            kb_reply = kb_manager.chat_with_knowledge_base(
                knowledge_id=kb_id,
                question=user_msg,
                stream=False
            )
        except Exception as e:
            kb_reply = f"çŸ¥è¯†åº“æ£€ç´¢å‡ºé”™ï¼š{e}"

        # æ„å»º Prompt
        prompt_parts = [f"ç”¨æˆ·ä¸ªäººä¿¡æ¯ï¼š{personal_info}"]
        if auto_info:
            prompt_parts.append(f"ç³»ç»Ÿè‡ªåŠ¨è¯†åˆ«ä¿¡æ¯ï¼š\n{auto_info}")
        prompt_parts.append(f"çŸ¥è¯†åº“å›å¤ï¼š\n{kb_reply}")
        prompt_parts.append(f"ç”¨æˆ·æ¶ˆæ¯ï¼š{user_msg}")
        prompt_parts.append("è¯·åŸºäºä¸Šè¿°ä¿¡æ¯ç»™å‡ºä¸“ä¸šã€å‡†ç¡®çš„ç³–å°¿ç—…ç®¡ç†å»ºè®®ã€‚å¿…é¡»ä½¿ç”¨ä¸­æ–‡å›ç­”")
        final_prompt = "\n".join(prompt_parts)
        logger.info("Final RAG Prompt to LLM: %s", final_prompt)

        # è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆæœ€ç»ˆå›å¤
        try:
            reply = llm._call(final_prompt)
        except Exception as e:
            reply = f"æ¨¡å‹è°ƒç”¨å‡ºé”™ï¼š{e}"
        history.append({"role": "assistant", "content": reply})

        # æ¸…ç©ºä¸Šä¼ åˆ—è¡¨
        return (
            history,
            history,
            [],
            gr.update(choices=[], value=[]),
            gr.update(value="")
        )


def on_generate_case(history, name=None, age=None, weight=None, gender=None, past_history=None):
    # åˆ¤æ–­ä¸ªäººä¿¡æ¯æ˜¯å¦å¡«å†™
    info_filled = any([name, age, weight, gender, past_history])
    # åˆ¤æ–­æ˜¯å¦æœ‰å¯¹è¯å†…å®¹ï¼ˆæ’é™¤åˆå§‹æ¬¢è¿è¯­ï¼‰
    dialog_filled = history and any(
        m["role"] == "user" and m["content"].strip() for m in history if m["role"] == "user"
    )

    # æƒ…å†µ1ï¼šä¸ªäººä¿¡æ¯å’Œå¯¹è¯éƒ½æ²¡æœ‰
    if not info_filled and not dialog_filled:
        return "æ²¡æœ‰ä¿¡æ¯å¯ä»¥ç”Ÿæˆç—…ä¾‹æŠ¥å‘Šå•ï¼Œè¯·å…ˆå¡«å†™ä¸ªäººä¿¡æ¯æˆ–è¿›è¡Œå¯¹è¯ã€‚"

    # æƒ…å†µ2ï¼šåªæœ‰ä¸ªäººä¿¡æ¯
    if info_filled and not dialog_filled:
        personal_info = (
            f"å§“åï¼š{name or 'æœªå¡«å†™'}\n"
            f"å¹´é¾„ï¼š{age or 'æœªå¡«å†™'}\n"
            f"ä½“é‡ï¼š{weight or 'æœªå¡«å†™'}\n"
            f"æ€§åˆ«ï¼š{gender or 'æœªå¡«å†™'}\n"
            f"æ—¢å¾€å²ï¼š{past_history or 'æœªå¡«å†™'}"
        )
        case_content = f"**ç—…ä¾‹æŠ¥å‘Šå•**\n\n{personal_info}"
        save_case_json(case_content, name=name)
        return case_content

    # æƒ…å†µ3ï¼šåªæœ‰å¯¹è¯å†…å®¹
    if not info_filled and dialog_filled:
        personal_info = (
            f"å§“åï¼šæ— \nå¹´é¾„ï¼šæ— \nä½“é‡ï¼šæ— \næ€§åˆ«ï¼šæ— \næ—¢å¾€å²ï¼šæ— "
        )
        hist = "\n".join(f"{m['role']}: {m['content']}" for m in history)
        case_p = (
            f"è¯·æ ¹æ®ä»¥ä¸‹å¯¹è¯ç”Ÿæˆç»“æ„åŒ–ç³–å°¿ç—…ç—…ä¾‹ï¼š\n\n"
            f"{personal_info}\n\n{hist}\n\n"
            "ç—…ä¾‹åº”åŒ…æ‹¬ï¼šç”¨æˆ·ä¸ªäººä¿¡æ¯(å§“åï¼Œå¹´é¾„ï¼Œä½“é‡ï¼Œæ€§åˆ«)ã€ä¸»è¯‰ã€ç°ç—…å²ã€æ—¢å¾€å²ã€æ£€æŸ¥ç»“æœã€åˆæ­¥è¯Šæ–­ã€ç®¡ç†å»ºè®®ã€‚æ§åˆ¶å­—æ•°åœ¨500å­—ä¹‹å†…"
            "æ³¨æ„åˆæ­¥è¯Šæ–­åº”è¯¥å†™ä¸ºä¹‹å‰å¯¹è¯å†å²æ‰€è®¤ä¸ºçš„æ‚£ç—…é£é™©"
        )
        logger.info("Case prompt to LLM: %s", case_p)
        try:
            case = llm._call(case_p)
        except Exception as e:
            case = f"ç”Ÿæˆç—…ä¾‹å‡ºé”™ï¼š{e}"
            return case
        save_case_json(case)
        return case

    # æƒ…å†µ4ï¼šä¸ªäººä¿¡æ¯å’Œå¯¹è¯éƒ½æœ‰
    personal_info = (
        f"å§“åï¼š{name or 'æœªå¡«å†™'}ï¼›å¹´é¾„ï¼š{age or 'æœªå¡«å†™'}ï¼›ä½“é‡ï¼š{weight or 'æœªå¡«å†™'}ï¼›"
        f"æ€§åˆ«ï¼š{gender or 'æœªå¡«å†™'}ï¼›æ—¢å¾€å²ï¼š{past_history or 'æœªå¡«å†™'}"
    )
    hist = "\n".join(f"{m['role']}: {m['content']}" for m in history)
    case_p = (
        f"è¯·æ ¹æ®ä»¥ä¸‹å¯¹è¯å’Œä¸ªäººä¿¡æ¯ç”Ÿæˆç»“æ„åŒ–ç³–å°¿ç—…ç—…ä¾‹ï¼š\n\n"
        f"{personal_info}\n\n{hist}\n\n"
        "ç—…ä¾‹åº”åŒ…æ‹¬ï¼šç”¨æˆ·ä¸ªäººä¿¡æ¯(å§“åï¼Œå¹´é¾„ï¼Œä½“é‡ï¼Œæ€§åˆ«)ã€ä¸»è¯‰ã€ç°ç—…å²ã€æ—¢å¾€å²ã€æ£€æŸ¥ç»“æœã€åˆæ­¥è¯Šæ–­ã€ç®¡ç†å»ºè®®ã€‚æ§åˆ¶å­—æ•°åœ¨500å­—ä¹‹å†…"
    )
    logger.info("Case prompt to LLM: %s", case_p)
    try:
        case = llm._call(case_p)
    except Exception as e:
        case = f"ç”Ÿæˆç—…ä¾‹å‡ºé”™ï¼š{e}"
        return case
    save_case_json(case, name=name)
    return case

def on_clear_history():
    welcome_msg = [{"role": "assistant", "content": "æ‚¨å¥½ï¼Œæˆ‘æ˜¯ç³–å°¿ç—…ä¸“ä¸šåŠ©æ‰‹ï¼Œè¯·æ‚¨æä¾›è¯¦ç»†ç—…ä¾‹ä¿¡æ¯ï¼Œä»¥ä¾¿æˆ‘ä¸ºæ‚¨é‡èº«å®šåˆ¶åŒ»å­¦å»ºè®®ã€‚ä½ æœ‰å…³äºæœ€è¿‘çš„æŠ¥å‘Šå¯ä»¥ç»™æˆ‘çœ‹çœ‹å—"}]
    return welcome_msg, welcome_msg, "**ç—…ä¾‹è®°å½•**\n\nå°šæ— å†…å®¹"

demo = build_ui(
    on_file_upload,
    on_delete,
    on_send,
    on_clear_history,
    on_generate_case
)

if __name__ == "__main__":
    demo.launch(inbrowser=True)
