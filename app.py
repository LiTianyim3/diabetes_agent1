import os
import base64
import logging
import gradio as gr
from client.zhipu_llm import ZhipuLLM
import datetime
from tools.case_json_manager import save_case_json
import json


KEY_MAP = {
    "ç©ºè…¹è¡€ç³–":       "ç©ºè…¹è¡€ç³–(GLUO)",
    "åŠå°æ—¶è¡€ç³–":     "åŠå°æ—¶è¡€ç³–(GLU0.5)",   # å¦‚æœè§£æå™¨è¾“å‡ºâ€œåŠå°æ—¶è¡€ç³–â€æƒ³å¡«åˆ°â€œäºŒå°æ—¶è¡€ç³–(GLU2)â€é‡Œï¼Œè¯·æŒ‰éœ€è°ƒæ•´
    "ä¸€å°æ—¶è¡€ç³–":     "ä¸€å°æ—¶è¡€ç³–(GLU1)",
    "ä¸¤å°æ—¶è¡€ç³–":     "ä¸¤å°æ—¶è¡€ç³–(GLU2)",
    "ä¸‰å°æ—¶è¡€ç³–":     "ä¸‰å°æ—¶è¡€ç³–(GLU3)",
    "ç³–åŒ–è¡€çº¢è›‹ç™½":   "ç³–åŒ–è¡€çº¢è›‹ç™½(HbA1C)",
    "ç©ºè…¹è¡€ç³–(GLUO)": "ç©ºè…¹è¡€ç³–",
    "åŠå°æ—¶è¡€ç³–(GLUO0.5)":     "åŠå°æ—¶è¡€ç³–",   # å¦‚æœè§£æå™¨è¾“å‡ºâ€œåŠå°æ—¶è¡€ç³–â€æƒ³å¡«åˆ°â€œäºŒå°æ—¶è¡€ç³–(GLU2)â€é‡Œï¼Œè¯·æŒ‰éœ€è°ƒæ•´
    "ä¸€å°æ—¶è¡€ç³–(GLU1)":     "ä¸€å°æ—¶è¡€ç³–",
    "ä¸¤å°æ—¶è¡€ç³–(GLU2)":     "ä¸¤å°æ—¶è¡€ç³–",
    "ä¸‰å°æ—¶è¡€ç³–(GLU3)":     "ä¸‰å°æ—¶è¡€ç³–",
    "ç³–åŒ–è¡€çº¢è›‹ç™½(HbA1C)":   "ç³–åŒ–è¡€çº¢è›‹ç™½",
    "BMI":           "BMI",
    "èº«é«˜":           None,  # ä¸éœ€è¦æç¤ºæ—¶å¯è®¾ä¸º None
    "ä½“é‡":           None,
    "æ”¶ç¼©å‹":         "è¡€å‹æ”¶ç¼©å‹",
    "èˆ’å¼ å‹":         "è¡€å‹èˆ’å¼ å‹",
    "å¿ƒç‡":           "é™æ¯å¿ƒç‡",
    "ä½“æ¸©":           "ä½“æ¸©",
    # â€¦â€¦å¦‚æœ‰å…¶å®ƒå­—æ®µï¼ŒæŒ‰å®é™…è¡¥å……
}

INDICATORS = {
    "ç—‡çŠ¶": {
        "prompt":
            "ä¸ºäº†æ›´å¥½åœ°äº†è§£æ‚¨çš„æƒ…å†µï¼Œ"
            "è¯·æ‚¨å›æƒ³æœ€è¿‘æ˜¯å¦å‡ºç°ä»¥ä¸‹ç—‡çŠ¶â€”â€”"
            "å¦‚å£æ¸´ã€æ’å°¿å¢å¤šæˆ–é£Ÿé‡æ˜æ˜¾å¢åŠ ï¼Ÿ",
        "value": None
    },
    "ç©ºè…¹è¡€ç³–": {
        "prompt":
            "æ¸…æ™¨ç©ºè…¹æ—¶ï¼ˆæœªè¿›é£Ÿè‡³å°‘8å°æ—¶ï¼‰ï¼Œ"
            "æ‚¨çš„è¡€ç³–å¤§çº¦æ˜¯å¤šå°‘ï¼Ÿ"
            "è¯·ç›´æ¥è¾“å…¥æ•°å€¼ï¼ˆmmol/Lï¼‰ã€‚",
        "value": None
    },
    "ä¸¤å°æ—¶è¡€ç³–": {
        "prompt": "åœ¨è¿›é¤åä¸¤å°æ—¶å†…æµ‹å¾—çš„è¡€ç³–å€¼æ˜¯å¤šå°‘ï¼Ÿ",
        "value": None
    },
    "ç³–åŒ–è¡€çº¢è›‹ç™½": {
        "prompt": "æœ€è¿‘ä¸€æ¬¡ç³–åŒ–è¡€çº¢è›‹ç™½ï¼ˆHbA1cï¼‰æ£€æµ‹ç»“æœæ˜¯å¤šå°‘ï¼Ÿ",
        "value": None
    },
    "BMI": {
        "prompt":
            "BMIï¼ˆä½“è´¨æŒ‡æ•°ï¼‰ç”¨äºè¯„ä¼°ä½“é‡æ˜¯å¦åœ¨å¥åº·èŒƒå›´ï¼Œ"
            "ä¸ç³–å°¿ç—…é£é™©å¯†åˆ‡ç›¸å…³ã€‚"
            "è¯·æ‚¨å‘Šè¯‰æˆ‘æ‚¨çš„ BMI å€¼ï¼ˆkg/mÂ²ï¼Œä»…æ•°å­—ï¼‰ï¼Œ",
        "value": None
    },
    "è¡€å‹æ”¶ç¼©å‹": {
        "prompt": "è¯·æä¾›æ”¶ç¼©å‹ SBPï¼ˆmmHgï¼Œä»…æ•°å­—ï¼‰",
        "value": None
    },
    "è¡€å‹èˆ’å¼ å‹": {
        "prompt": "è¯·æä¾›èˆ’å¼ å‹ DBPï¼ˆmmHgï¼Œä»…æ•°å­—ï¼‰",
        "value": None
    },
    "é™æ¯å¿ƒç‡": {
        "prompt": "è¯·æä¾›é™æ¯å¿ƒç‡ HRï¼ˆæ¬¡/åˆ†ï¼Œä»…æ•°å­—ï¼‰",
        "value": None
    },
    "äº²å±ç³–å°¿ç—…ç—…å²": {
        "prompt": "æ‚¨æ˜¯å¦æœ‰ä¸€çº§äº²å±ç³–å°¿ç—…ç—…å²æˆ–è€…å®¶æ—å²ï¼Ÿ",
        "value": None
    },
    "å…¶ä»–é‡è¦è¯´æ˜": {
        "prompt":
            "å¦‚æœæ‚¨æœ‰æ­£åœ¨ä½¿ç”¨çš„è¯ç‰©ã€ç‰¹æ®Šé¥®é£Ÿæˆ–è¿åŠ¨ä¹ æƒ¯ç­‰ï¼Œ"
            "è¿™ä¼šå¸®åŠ©æˆ‘ä»¬æ›´å…¨é¢åœ°äº†è§£æ‚¨çš„å¥åº·çŠ¶å†µã€‚"
            "è¯·æ‚¨è¡¥å……å…¶ä»–é‡è¦è¯´æ˜ï¼š",
        "value": None
    }
}

from neo4j import GraphDatabase

neo_driver = GraphDatabase.driver(
    "bolt://localhost:7687",
    auth=("neo4j", "415zc415")
)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s: %(message)s"
)
logger = logging.getLogger(__name__)
llm = ZhipuLLM()

DATA_DIR = os.path.join(os.path.dirname(__file__), "data")
os.makedirs(DATA_DIR, exist_ok=True)

# CSSï¼šå·¦ä¾§ Ã— å›¾æ ‡ & æ‚¬åœé«˜äº®
css = """
#file-selector .gr-checkbox {
  padding: 8px 8px 8px 28px;
  position: relative;
  border-radius: 4px;
  transition: background-color 0.2s;
}
/* Ã— å›¾æ ‡æ”¾åœ¨å·¦ä¾§ */
#file-selector .gr-checkbox:hover::before {
  content: "Ã—";
  position: absolute;
  left: 8px;
  top: 50%;
  transform: translateY(-50%);
  color: #e00;
  font-size: 16px;
  cursor: pointer;
}
/* æ‚¬åœé«˜äº® */
#file-selector .gr-checkbox:hover {
  background-color: #f5f5f5;
}
/* é™åˆ¶æ¸…é™¤æŒ‰é’®å®½åº¦ */
#clear-btn {
  min-width: 30px;
  max-width: 60px;
}
"""

QUESTIONS = [
    "1/4 æ‚¨æ˜¯å¦æœ‰å¤šå°¿ã€å¤šé¥®ã€å¤šé£Ÿç­‰é«˜è¡€ç³–ç—‡çŠ¶ï¼Ÿï¼ˆæœ‰ / æ— ï¼‰",
    "2/4 æ‚¨çš„ç©ºè…¹è¡€ç³–ï¼ˆFPGï¼‰æ˜¯å¤šå°‘ï¼Ÿï¼ˆmmol/Lï¼‰",
    "3/4 æ‚¨çš„é¤å 2 å°æ—¶è¡€ç³–æ˜¯å¤šå°‘ï¼Ÿï¼ˆmmol/Lï¼‰",
    "4/4 æ‚¨çš„ HbA1cï¼ˆç³–åŒ–è¡€çº¢è›‹ç™½ï¼‰æ˜¯å¤šå°‘ï¼Ÿï¼ˆ%ï¼‰",
]

def _query_graph(answers: dict):
    """
    answers = {"sym": "æœ‰/æ— ", "fpg": "7.8", "pp2h": "12.0", "hb": "6.8"}
    è¿”å›å»é‡åçš„è¯Šæ–­åç§°åˆ—è¡¨ï¼ˆå¯èƒ½ä¸ºç©ºï¼‰
    """
    cypher = """
    WITH $sym AS sym,
         toFloat($fpg)  AS fpg,
         toFloat($pp2h) AS pp2h,
         toFloat($hb)   AS hb
    OPTIONAL MATCH (s:Symptom {name:'å…¸å‹é«˜è¡€ç³–ç—‡çŠ¶'})-[:LEADS_TO]->(d1:Diagnosis)
      WHERE sym = 'æœ‰'
    OPTIONAL MATCH (i1:Indicator {name:'FPG'})-[:LEADS_TO]->(d2:Diagnosis)
      WHERE fpg >= i1.threshold
    OPTIONAL MATCH (i2:Indicator {name:'PostPrandial2H'})-[:LEADS_TO]->(d3:Diagnosis)
      WHERE pp2h >= i2.threshold
    OPTIONAL MATCH (i3:Indicator {name:'HbA1c'})-[:LEADS_TO]->(d4:Diagnosis)
      WHERE hb >= i3.threshold
    RETURN
      collect(d1.name) + collect(d2.name) +
      collect(d3.name) + collect(d4.name) AS all_names
    """
    with neo_driver.session(bookmarks=None) as s:
        rec = s.run(cypher, **answers).single()
        raw = rec["all_names"] if rec else []
        # è¿‡æ»¤ None / ç©ºä¸²ï¼Œå†å»é‡
        return list({n for n in raw if n})

def gen_followup_question(answers: dict, asked: list[str]) -> str:
    """
    answers : å·²æ”¶é›†çš„å›ç­” dict
    asked   : å·²ç»é—®è¿‡çš„é—®é¢˜æ–‡æœ¬åˆ—è¡¨
    """
    prompt = (
        "ä½ æ˜¯ä¸€åå†…åˆ†æ³Œç§‘åŒ»ç”Ÿï¼Œæ­£åœ¨åšç³–å°¿ç—…é—®è¯Šã€‚\n"
        "ä»¥ä¸‹é—®é¢˜å·²ç»é—®è¿‡ï¼Œç¦æ­¢é‡å¤ï¼š\n" +
        "\n".join(f"- {q}" for q in asked) + "\n\n"
        "å·²è·å›ç­”ï¼š\n"
        f"å…¸å‹ç—‡çŠ¶={answers.get(0,'æœªå›ç­”')}ï¼›"
        f"FPG={answers.get(1,'æœªå›ç­”')}ï¼›"
        f"é¤å2h={answers.get(2,'æœªå›ç­”')}ï¼›"
        f"HbA1c={answers.get(3,'æœªå›ç­”')}\n"
        "è¯·æå‡ºä¸‹ä¸€æ¡æœ€å…³é”®ä¸”ä¸é‡å¤çš„é—®é¢˜ï¼Œ"
        "è¦æ±‚ï¼šç”¨ä¸­æ–‡ã€ç®€æ´ï¼Œä¸”åªè¾“å‡ºé—®é¢˜æœ¬èº«ã€‚"
    )
    try:
        q = llm._call(prompt).strip()
    except Exception:
        q = ""
    return q or "è¯·æä¾›å…¶ä»–ä¸è¡€ç³–ç›¸å…³çš„æ£€æŸ¥æˆ–ç—‡çŠ¶ä¿¡æ¯ï¼Ÿ"

def guided_on_send(text, file_list, history_state,
                   name, age, weight, gender, past_history):
    history, step, answers = history_state
    user_text = (text or "").strip()

    # æ”¶é›†ä¸Šä¸€æ­¥å›ç­”
    if step > 0:
        answers[step-1] = user_text
        history.append({"role":"user","content":user_text})

    # è¿˜æ²¡é—®å®Œ â‡’ ç»§ç»­æé—®
    if step < len(QUESTIONS):
        q = QUESTIONS[step]
        history.append({"role":"assistant","content":q})
        step += 1
        return history, (history, step, answers), file_list, gr.update(), gr.update(value="")

    diag_list = _query_graph({
        "sym":  answers.get(0, "æ— "),
        "fpg":  answers.get(1, "0"),
        "pp2h": answers.get(2, "0"),
        "hb":   answers.get(3, "0")
    })
    MAX_EXTRA_QUESTIONS = 5   # æœ€å¤šç»§ç»­è¿½é—® 5 æ¬¡
    MAX_RETRY = 3          # ç”Ÿæˆä¸é‡å¤é—®é¢˜æœ€å¤šé‡è¯• 3 æ¬¡
    
    if diag_list:
        reply = "åˆæ­¥å¯èƒ½è¯Šæ–­ç±»å‹ï¼š" + "ã€".join(diag_list)
        history.append({"role":"assistant","content":reply})
        # ç»“æŸï¼šé‡ç½® state
        new_state = ([{"role":"assistant","content":"å¦‚éœ€å†æ¬¡é—®è¯Šï¼Œè¯·è¾“å…¥ä»»æ„å†…å®¹ã€‚"}], 0, {})
        return history, new_state, [], gr.update(), gr.update(value="")

    # â”€â”€ è‹¥ä»æœªè¯Šæ–­ï¼Œè‡ªåŠ¨ç”Ÿæˆä¸‹ä¸€æ¡é—®é¢˜ â”€â”€
    if step - 4 >= MAX_EXTRA_QUESTIONS:
        reply = "å·²è¿½é—®å¤šæ¬¡ä»æ— æ³•ç»™å‡ºè¯Šæ–­ï¼Œå»ºè®®æºå¸¦å®Œæ•´æ£€æŸ¥æŠ¥å‘Šå°±åŒ»ã€‚"
        history.append({"role":"assistant","content":reply})
        new_state = ([{"role":"assistant","content":"å¦‚éœ€å†æ¬¡é—®è¯Šï¼Œè¯·è¾“å…¥ä»»æ„å†…å®¹ã€‚"}], 0, {})
        return history, new_state, [], gr.update(), gr.update(value="")

    asked_texts = [m["content"] for m in history if m["role"] == "assistant" and m["content"].endswith("ï¼Ÿ")]
    for _ in range(MAX_RETRY):
        next_q = gen_followup_question(answers, asked_texts)
        if next_q not in asked_texts:
            break
    else:  # ä¸‰æ¬¡éƒ½é‡å¤ï¼Œå°±ç»™å…œåº•é—®é¢˜
        next_q = "è¯·å‘Šè¯‰æˆ‘ä»»ä½•æœ€è¿‘è¡€ç³–ç›¸å…³çš„å¼‚å¸¸æ£€æŸ¥é¡¹ç›®ï¼Ÿ"

    history.append({"role":"assistant","content":next_q})
    step += 1
    return history, (history, step, answers), file_list, gr.update(), gr.update(value="")



def on_file_upload(file_paths, history, file_list):
    history   = history   or []
    file_list = file_list or []

    # å¦‚æœæ²¡é€‰æ–°æ–‡ä»¶ï¼Œä»…åˆ·æ–°åˆ—è¡¨
    if not file_paths:
        opts = [os.path.basename(p) for p in file_list]
        return history, history, file_list, gr.update(choices=opts, value=[])

    paths = file_paths if isinstance(file_paths, list) else [file_paths]

    from tools.lab_report_parser import parse_lab_report

    for p in paths:
        if p in file_list:
            continue
        file_list.append(p)
        name = os.path.basename(p)
        ext  = os.path.splitext(name)[1].lower().lstrip(".")

        with open(p, "rb") as f:
            file_bytes = f.read()
            b64 = base64.b64encode(file_bytes).decode("utf-8")

        # èŠå¤©åŒºæ’å…¥å›¾ç‰‡/æ–‡ä»¶
        if ext in ("png","jpg","jpeg"):
            md = f"![{name}](data:image/{ext};base64,{b64})"
            history.append({"role":"system", "content":f"å·²ä¸Šä¼ å›¾ç‰‡ï¼š{name}\n\n{md}"})
            # è‡ªåŠ¨è§£æå›¾ç‰‡åŒ»å­¦æŒ‡æ ‡
            result = parse_lab_report(file_bytes)
            print(result)
            # è‡ªåŠ¨éå†æ‰€æœ‰éç©ºåŒ»å­¦æŒ‡æ ‡å¹¶å±•ç¤ºï¼ˆç›´æ¥ç”¨ä¸­æ–‡keyï¼‰
            if any(result.values()):
                summary = []
                user_features = {}
                # keyæ˜ å°„ï¼šä¸­æ–‡key->æ•°æ®é›†è‹±æ–‡key
                key_map = {
                    "æ€§åˆ«": "gender",
                    "å¹´é¾„": "age",
                    "é«˜è¡€å‹": "hypertension",
                    "å¿ƒè„ç—…": "heart_disease",
                    "å¸çƒŸå²": "smoking_history",
                    "BMI": "bmi",
                    "ç³–åŒ–è¡€çº¢è›‹ç™½": "HbA1c_level",
                    "ç©ºè…¹è¡€ç³–": "blood_glucose_level",
                    "ä¸¤å°æ—¶è¡€ç³–": "blood_glucose_level",
                    "ç³–å°¿ç—…": "diabetes",
                    # å¯æ ¹æ®å®é™…æ•°æ®é›†ç»§ç»­è¡¥å……
                }
                import re
                for k, v in result.items():
                    if v is not None:
                        summary.append(f"{k}: {v}")
                        mapped_key = key_map.get(k, k)
                        num = None
                        try:
                            num = float(v)
                        except Exception:
                            match = re.search(r"[-+]?[0-9]*\\.?[0-9]+", str(v))
                            if match:
                                try:
                                    num = float(match.group())
                                except Exception:
                                    pass
                        if num is not None:
                            user_features[mapped_key] = num
                        # è‡ªåŠ¨å¡«å……åˆ°INDICATORS valueå­—æ®µ
                        if k in INDICATORS and v not in (None, ""):
                            INDICATORS[k]["value"] = str(v)
                if summary:
                    history.append({"role": "system", "content": "è‡ªåŠ¨è¯†åˆ«ä¿¡æ¯ï¼š\n" + "\\n".join(summary)})
                # è‡ªåŠ¨è§¦å‘RAGæ£€ç´¢
                if user_features:
                    from rag.index_diabetes import generate_scientific_advice
                    rag_info = generate_scientific_advice(user_features)
                    history.append({"role": "system", "content": "ã€æ•°æ®é›†ç›¸ä¼¼ç—…ä¾‹å‚è€ƒã€‘\n" + rag_info})
        elif ext == "pdf":
            md = f"[ğŸ“„ {name}](data:application/pdf;base64,{b64})"
            history.append({"role":"system","content":f"å·²ä¸Šä¼  PDFï¼š{md}"})
            # è‡ªåŠ¨è§£æ PDF åŒ»å­¦æŒ‡æ ‡
            result = parse_lab_report(file_bytes)
            if any(result.values()):
                summary = []
                for k, v in result.items():
                    if v is not None:
                        summary.append(f"{k}: {v}")
                if summary:
                    history.append({"role": "system", "content": "è‡ªåŠ¨è¯†åˆ«ä¿¡æ¯ï¼š\n" + "\n".join(summary)})
        else:
            history.append({"role":"system","content":f"å·²ä¸Šä¼ æ–‡ä»¶ï¼š{name}"})

    opts = [os.path.basename(p) for p in file_list]
    return history, history, file_list, gr.update(choices=opts, value=[])

def on_delete(selected, file_list):
    # ç‚¹å‡»å‹¾é€‰å³åˆ é™¤
    file_list = file_list or []
    remaining = [p for p in file_list if os.path.basename(p) not in (selected or [])]
    opts = [os.path.basename(p) for p in remaining]
    return remaining, gr.update(choices=opts, value=[])

def on_send(text, file_list, history, name, age, weight, gender, past_history):
    history   = history or []
    user_msg  = text or ""

    if file_list:
        names = ", ".join(os.path.basename(p) for p in file_list)
        suffix = f"[å·²ä¸Šä¼ æ–‡ä»¶ï¼š{names}]"
        user_msg = f"{user_msg}\n{suffix}" if user_msg else suffix
    history.append({"role":"user","content":user_msg})

    
    # ä¼˜å…ˆåˆ¤æ–­æ˜¯å¦æœ‰è‡ªåŠ¨è¯†åˆ«çš„æ•°å€¼å‹æŒ‡æ ‡
    auto_features = {}
    for key, info in INDICATORS.items():
        value = info["value"]
        try:
            num = float(value)
            auto_features[key] = num
        except Exception:
            pass
    if auto_features:
        # å·²æœ‰è‡ªåŠ¨è¯†åˆ«æ•°å€¼ï¼Œç›´æ¥è¿›å…¥LLMå»ºè®®å’ŒRAG
        pass
    else:
        # æ²¡æœ‰è‡ªåŠ¨è¯†åˆ«æ•°å€¼ï¼Œé€é¡¹é—®è¯¢
        for key, info in INDICATORS.items():
            prompt_text = info["prompt"]
            value = info["value"]
            print(f"æŒ‡æ ‡åï¼š{key}ï¼Œæç¤ºè¯­ï¼š{prompt_text}ï¼Œå·²å¡«å€¼ï¼š{value}")
            if value is None:
                history.append({
                    "role": "assistant",
                    "content": prompt_text
                })
                INDICATORS[key]["value"] = user_msg
                return (
                    history,                                     
                    history,                                     
                    file_list,                                   
                    gr.update(choices=[os.path.basename(p) for p in file_list], value=[]), 
                    gr.update(value="")                         
                )

    # ä»…æ‹¼æ¥å·²ä¸Šä¼ æ–‡ä»¶ä¿¡æ¯
    if file_list:
        names = ", ".join(os.path.basename(p) for p in file_list)
        user_msg = (user_msg + "\n" if user_msg else "") + f"[å·²ä¸Šä¼ æ–‡ä»¶ï¼š{names}]"
    # ç”¨æˆ·æ¶ˆæ¯ç›´æ¥ä¼ é€’ï¼ˆå‰ç«¯ä¸æ˜¾ç¤ºä¸ªäººä¿¡æ¯ï¼‰
    history.append({"role":"user","content":user_msg})

    # æ‹¼æ¥ä¸ªäººä¿¡æ¯ï¼ˆåç«¯ä¼ ç»™æ¨¡å‹ï¼Œä¸æ˜¾ç¤ºåœ¨èŠå¤©åŒºï¼‰
    personal_info = (
        f"å§“åï¼š{name or 'æœªå¡«å†™'}ï¼›å¹´é¾„ï¼š{age or 'æœªå¡«å†™'}ï¼›ä½“é‡ï¼š{weight or 'æœªå¡«å†™'}ï¼›"
        f"æ€§åˆ«ï¼š{gender or 'æœªå¡«å†™'}ï¼›æ—¢å¾€å²ï¼š{past_history or 'æœªå¡«å†™'}"
    )

    # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡/æŠ¥å‘Šè‡ªåŠ¨è¯†åˆ«ä¿¡æ¯
    auto_info = None
    for m in reversed(history):
        if m["role"] == "system" and m["content"].startswith("è‡ªåŠ¨è¯†åˆ«ä¿¡æ¯ï¼š"):
            auto_info = m["content"]
            break

    # LLM å»ºè®®
    if auto_info:
        # ä»historyä¸­æŸ¥æ‰¾ragæ£€ç´¢ç»“æœ
        rag_info = ''
        for m in reversed(history):
            if m["role"] == "system" and m["content"].startswith("ã€æ•°æ®é›†ç›¸ä¼¼ç—…ä¾‹å‚è€ƒã€‘"):
                rag_info = m["content"]
                break
        if rag_info:
            rag_info = f"{rag_info}\n"
        prompt = (
            f"ç”¨æˆ·ä¸ªäººä¿¡æ¯ï¼š{personal_info}\n"
            f"ç”¨æˆ·ä¸Šä¼ äº†åŒ»å­¦æŠ¥å‘Šæˆ–å›¾ç‰‡ï¼Œç³»ç»Ÿè‡ªåŠ¨è¯†åˆ«å‡ºå¦‚ä¸‹ç»“æ„åŒ–ä¿¡æ¯ï¼š\n{auto_info}\n"
            f"{rag_info}"
            f"è¯·åŸºäºè¿™äº›åŒ»å­¦ä¿¡æ¯ï¼Œç»“åˆç”¨æˆ·æ¶ˆæ¯â€œ{user_msg}â€ï¼Œå¹¶æ¢å¤åœ¨user_msgä¸­äº†è§£äº†ä»€ä¹ˆï¼Œä¸ç”¨è§£é‡Šäº†è§£çš„ä¿¡æ¯ã€‚"
            "å¦‚æœä¿¡æ¯ä¸å…¨å¯é€‚å½“è¯´æ˜ï¼Œä½†ä¸è¦è¯´æ— æ³•è¯†åˆ«å›¾ç‰‡ã€‚"
        )
    else:
        prompt = (
            f"ç”¨æˆ·ä¸ªäººä¿¡æ¯ï¼š{personal_info}\n"
            f"ç”¨æˆ·æ¶ˆæ¯ï¼š{user_msg}\nå¹¶æ¢å¤åœ¨user_msgä¸­äº†è§£äº†ä»€ä¹ˆï¼Œä¸ç”¨è§£é‡Šäº†è§£çš„ä¿¡æ¯ã€‚"
        )
    logger.info("Prompt to LLM: %s", prompt)
    try: reply = llm._call(prompt)
    except Exception as e: reply = f"æ¨¡å‹è°ƒç”¨å‡ºé”™ï¼š{e}"
    history.append({"role":"assistant","content":reply})

    # å‘é€åæ¸…ç©ºå·²ä¸Šä¼ åˆ—è¡¨ï¼Œä¸å†è‡ªåŠ¨ç”Ÿæˆç—…ä¾‹
    return history, history, [], gr.update(choices=[], value=[]), gr.update(value="")

def on_generate_case(history, name=None, age=None, weight=None, gender=None, past_history=None):
    info_filled = any([name, age, weight, gender, past_history])
    dialog_filled = history and any(
        m["role"] == "user" and m["content"].strip() for m in history if m["role"] == "user"
    )

    # æƒ…å†µ1ï¼šä¸ªäººä¿¡æ¯å’Œå¯¹è¯éƒ½æ²¡æœ‰
    if not info_filled and not dialog_filled:
        return "æ²¡æœ‰ä¿¡æ¯å¯ä»¥ç”Ÿæˆç—…ä¾‹æŠ¥å‘Šå•ï¼Œè¯·å…ˆå¡«å†™ä¸ªäººä¿¡æ¯æˆ–è¿›è¡Œå¯¹è¯ã€‚"

    # æƒ…å†µ2ï¼šåªæœ‰ä¸ªäººä¿¡æ¯
    if info_filled and not dialog_filled:
        case_dict = {
            "å§“å": name or "æœªå¡«å†™",
            "å¹´é¾„": age or "æœªå¡«å†™",
            "ä½“é‡": weight or "æœªå¡«å†™",
            "æ€§åˆ«": gender or "æœªå¡«å†™",
            "æ—¢å¾€å²": past_history or "æœªå¡«å†™"
        }
        save_case_json(case_dict, name, DATA_DIR)
        personal_info = (
            f"å§“åï¼š{case_dict['å§“å']}\n"
            f"å¹´é¾„ï¼š{case_dict['å¹´é¾„']}\n"
            f"ä½“é‡ï¼š{case_dict['ä½“é‡']}\n"
            f"æ€§åˆ«ï¼š{case_dict['æ€§åˆ«']}\n"
            f"æ—¢å¾€å²ï¼š{case_dict['æ—¢å¾€å²']}"
        )
        return f"**ç—…ä¾‹æŠ¥å‘Šå•**\n\n{personal_info}"

    # æƒ…å†µ3ï¼šåªæœ‰å¯¹è¯å†…å®¹
    if not info_filled and dialog_filled:
        personal_info = {
            "å§“å": "æ— ", "å¹´é¾„": "æ— ", "ä½“é‡": "æ— ", "æ€§åˆ«": "æ— ", "æ—¢å¾€å²": "æ— "
        }
        hist = "\n".join(f"{m['role']}: {m['content']}" for m in history)
        case_p = (
            f"è¯·æ ¹æ®ä»¥ä¸‹å¯¹è¯ç”Ÿæˆç»“æ„åŒ–ç³–å°¿ç—…ç—…ä¾‹ï¼š\n\n"
            f"å§“åï¼šæ— \nå¹´é¾„ï¼šæ— \nä½“é‡ï¼šæ— \næ€§åˆ«ï¼šæ— \næ—¢å¾€å²ï¼šæ— \n\n{hist}\n\n"
            "ç—…ä¾‹åº”åŒ…æ‹¬ï¼šç”¨æˆ·ä¸ªäººä¿¡æ¯(å§“åï¼Œå¹´é¾„ï¼Œä½“é‡ï¼Œæ€§åˆ«)ã€ä¸»è¯‰ã€ç°ç—…å²ã€æ—¢å¾€å²ã€æ£€æŸ¥ç»“æœã€åˆæ­¥è¯Šæ–­ã€ç®¡ç†å»ºè®®ã€‚æ§åˆ¶å­—æ•°åœ¨500å­—ä¹‹å†…"
        )
        logger.info("Case prompt to LLM: %s", case_p)
        try:
            case = llm._call(case_p)
        except Exception as e:
            case = f"ç”Ÿæˆç—…ä¾‹å‡ºé”™ï¼š{e}"
            return case
        # å°è¯•è§£æä¸º dict å¹¶ä¿å­˜
        try:
            case_dict = json.loads(case)
        except Exception:
            case_dict = {"å†…å®¹": case}
        save_case_json(case_dict, None, DATA_DIR)
        return case

    # æƒ…å†µ4ï¼šä¸ªäººä¿¡æ¯å’Œå¯¹è¯éƒ½æœ‰
    personal_info = (
        f"å§“åï¼š{name or 'æœªå¡«å†™'}ï¼›å¹´é¾„ï¼š{age or 'æœªå¡«å†™'}ï¼›ä½“é‡ï¼š{weight or 'æœªå¡«å†™'}ï¼›"
        f"æ€§åˆ«ï¼š{gender or 'æœªå¡«å†™'}ï¼›æ—¢å¾€å²ï¼š{past_history or 'æœªå¡«å†™'}"
    )
    hist = "\n".join(f"{m['role']}: {m['content']}" for m in history)
    case_p = (
        f"è¯·æ ¹æ®ä»¥ä¸‹å¯¹è¯å’Œä¸ªäººä¿¡æ¯ç”Ÿæˆç»“æ„åŒ–ç³–å°¿ç—…ç—…ä¾‹ï¼š\n\n"
        f"{personal_info}\n\n{hist}\n\n"
        "ç—…ä¾‹åº”åŒ…æ‹¬ï¼šç”¨æˆ·ä¸ªäººä¿¡æ¯(å§“åï¼Œå¹´é¾„ï¼Œä½“é‡ï¼Œæ€§åˆ«)ã€ä¸»è¯‰ã€ç°ç—…å²ã€æ—¢å¾€å²ã€æ£€æŸ¥ç»“æœã€åˆæ­¥è¯Šæ–­ã€ç®¡ç†å»ºè®®ã€‚æ§åˆ¶å­—æ•°åœ¨500å­—ä¹‹å†…"
    )
    logger.info("Case prompt to LLM: %s", case_p)
    try:
        case = llm._call(case_p)
    except Exception as e:
        case = f"ç”Ÿæˆç—…ä¾‹å‡ºé”™ï¼š{e}"
        return case
    # å°è¯•è§£æä¸º dict å¹¶ä¿å­˜
    try:
        case_dict = json.loads(case)
    except Exception:
        case_dict = {"å†…å®¹": case}
    save_case_json(case_dict, name, DATA_DIR)
    return case

def on_clear_history():
    welcome_msg = [{"role": "assistant", "content": "æ‚¨å¥½ï¼Œæˆ‘æ˜¯ç³–å°¿ç—…ä¸“ä¸šåŠ©æ‰‹ï¼Œè¯·æ‚¨æä¾›è¯¦ç»†ç—…ä¾‹ä¿¡æ¯ï¼Œä»¥ä¾¿æˆ‘ä¸ºæ‚¨é‡èº«å®šåˆ¶åŒ»å­¦å»ºè®®ã€‚ä½ æœ‰å…³äºæœ€è¿‘çš„æŠ¥å‘Šå¯ä»¥ç»™æˆ‘çœ‹çœ‹å—"}]
    return welcome_msg, welcome_msg, "**ç—…ä¾‹è®°å½•**\n\nå°šæ— å†…å®¹"

from ui.custom_ui import build_ui

demo = build_ui(
    on_file_upload=on_file_upload,
    on_delete=on_delete,
    on_send=on_send,
    on_clear_history=on_clear_history,
    on_generate_case=on_generate_case
)

if __name__ == "__main__":
    demo.launch(inbrowser=True)
