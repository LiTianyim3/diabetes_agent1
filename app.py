import json
import logging
import gradio as gr
import concurrent.futures
import time
from client.zhipu_llm import ZhipuLLM
from langchain.agents import Tool, AgentExecutor, create_structured_chat_agent
from langchain_core.prompts import ChatPromptTemplate
from tools.diabetes_classifier import classify_diabetes
from tools.exercise_advice import gen_exercise_advice
from tools.lab_report_parser import parse_lab_report_text
from tools.nutrition_advice import gen_nutrition_advice
from tools.severity_scoring import score_severity

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s %(name)s: %(message)s"
)
logger = logging.getLogger(__name__)

# åˆå§‹åŒ–æ™ºè°± AI LLM å’Œ Agent
llm = ZhipuLLM()
tools = [
    Tool("parse_lab", func=parse_lab_report_text,   description="è§£ææ£€éªŒæŠ¥å‘Šæ–‡æœ¬ï¼Œæå–è¡€ç³–ã€HbA1cç­‰æŒ‡æ ‡"),
    Tool("classify_dm", func=classify_diabetes,     description="åˆ¤æ–­æ˜¯å¦ç³–å°¿ç—…"),
    Tool("score_sev", func=score_severity,          description="åˆ†çº§ï¼šè½»/ä¸­/é‡"),
    Tool("nutrition", func=gen_nutrition_advice,    description="ç”Ÿæˆè¥å…»å»ºè®®"),
    Tool("exercise", func=gen_exercise_advice,      description="ç”Ÿæˆè¿åŠ¨å»ºè®®"),
]

# ç”¨ ChatPromptTemplate æ„é€  promptï¼ˆç®€åŒ–ä¸ºä¸å¯ç”¨é¡¹ç›®ä¸€è‡´ï¼‰
prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ä¸“ä¸šçš„ç³–å°¿ç—…å¥åº·åŠ©æ‰‹ï¼Œè¯·æ ¹æ®å·¥å…·å’Œç”¨æˆ·è¾“å…¥ç»™å‡ºä¸“ä¸šå»ºè®®ã€‚"),
    ("user", "{input}"),
    ("system", "å¯ç”¨å·¥å…·åŒ…æ‹¬ï¼š{tool_names}"),
    ("system", "å·¥å…·æ‰§è¡Œè®°å½•ï¼š{agent_scratchpad}"),
    ("system", "å·¥å…·åˆ—è¡¨ï¼š{tools}")
])

# åˆ›å»º AgentExecutorï¼ˆä¸å¯ç”¨é¡¹ç›®ä¸€è‡´ï¼‰
agent = AgentExecutor.from_agent_and_tools(
    agent=create_structured_chat_agent(llm=llm, tools=tools, prompt=prompt),
    tools=tools,
    verbose=False,
    handle_parsing_errors=True,
    max_iterations=15,           # å¢åŠ è¿­ä»£æ¬¡æ•°é™åˆ¶
    max_execution_time=60,       # å¢åŠ æœ€å¤§æ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰
)

# è§£ææŠ¥å‘Šæ‘˜è¦
def parse_report(report_text: str) -> str:
    logger.info("parse_report called with report_text: %r", report_text)
    if not report_text:
        return ""
    # æå–å¹¶æ—¥å¿—è¾“å‡ºç»“æ„åŒ–æ•°æ®
    data = parse_lab_report_text(report_text)
    logger.info("Extracted lab data: %s", data)
    # æ‹¼æ¥æ‘˜è¦ prompt
    lines = []
    if data.get("fasting_glucose") is not None:
        lines.append(f"- ç©ºè…¹è¡€ç³–: {data['fasting_glucose']} mmol/L")
    if data.get("hba1c") is not None:
        lines.append(f"- HbA1c: {data['hba1c']} %")
    if data.get("ogtt_2h") is not None:
        lines.append(f"- OGTT 2h è¡€ç³–: {data['ogtt_2h']} mmol/L")
    if data.get("bmi") is not None:
        lines.append(f"- BMI: {data['bmi']}")
    bullet_str = "\n".join(lines)
    prompt = (
        f"ä»¥ä¸‹æ˜¯æ‚£è€…çš„æ£€æŸ¥æŒ‡æ ‡ï¼š\n{bullet_str}\n"
        "è¯·ç”¨ä¸€æ®µä¸“ä¸šã€ç®€æ´çš„è‡ªç„¶è¯­è¨€ï¼Œæ¦‚æ‹¬ä¸Šè¿°æ£€æŸ¥ç»“æœåŠæ½œåœ¨é£é™©ã€‚"
    )
    logger.info("Summary prompt: %r", prompt)
    summary = llm._call(prompt)
    logger.info("Generated summary: %r", summary)
    return summary

# å›ç­”ç”¨æˆ·ç–‘é—®ï¼ˆä¸å¼ºåˆ¶ JSONï¼Œç›´æ¥è‡ªç„¶è¯­è¨€ï¼‰
def answer_question(report_summary, user_message, history):
    logger.info(f"answer_question called with report_summary: '{report_summary}' user_message: '{user_message}'")
    # å¿«é€Ÿé—®å€™åˆ†æ”¯
    if user_message.strip() in ["ä½ å¥½", "æ‚¨å¥½", "hi", "hello"]:
        bot_msg = "æ‚¨å¥½ï¼Œæˆ‘æ˜¯ç³–åŒ»åŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨ï¼Ÿ"
        history = history or []
        history.append([user_message, bot_msg])
        return history, history

    history = history or []
    bot_msg = "æ­£åœ¨ç”Ÿæˆï¼Œè¯·ç¨å€™..."
    history.append([user_message, bot_msg])

    # æ„é€ å¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡
    chat_history_str = ""
    for q, a in history[:-1]:  # ä¸åŒ…æ‹¬æœ¬è½®
        chat_history_str += f"ç”¨æˆ·ï¼š{q}\nåŠ©æ‰‹ï¼š{a}\n"
    chat_history_str += f"ç”¨æˆ·ï¼š{user_message}\n"

    # é’ˆå¯¹æœ‰æ— æŠ¥å‘Šæ‘˜è¦åˆ†åˆ«å¤„ç†
    if report_summary and report_summary.strip():
        prompt = (
            f"æ‚£è€…æŠ¥å‘Šæ‘˜è¦ï¼š\n{report_summary}\n\n"
            f"å¯¹è¯å†å²ï¼š\n{chat_history_str}"
            "è¯·ç»“åˆä¸Šè¿°ä¿¡æ¯ï¼Œç›´æ¥ç”¨ä¸“ä¸šç®€æ˜çš„è‡ªç„¶è¯­è¨€å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"
        )
    else:
        prompt = (
            f"å¯¹è¯å†å²ï¼š\n{chat_history_str}"
            "è¯·ç”¨ä¸“ä¸šç®€æ˜çš„è‡ªç„¶è¯­è¨€å®‰æŠšç”¨æˆ·ï¼Œå¹¶å¼•å¯¼å…¶è¡¥å……å¥åº·æ£€æŸ¥æŠ¥å‘Šæˆ–æè¿°å…·ä½“ç—‡çŠ¶ï¼Œæ— éœ€é‡å¤è¿½é—®ã€‚"
        )

    logger.info(f"Question prompt: '{prompt}'")
    try:
        with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
            future = executor.submit(agent.invoke, {"input": prompt}, handle_parsing_errors=True)
            agent_result = future.result(timeout=15)
        logger.info(f"Agent response: {agent_result}")
        if isinstance(agent_result, dict) and "output" in agent_result:
            bot_msg = agent_result["output"]
        else:
            bot_msg = str(agent_result)
    except concurrent.futures.TimeoutError:
        bot_msg = "å“åº”è¶…æ—¶ï¼Œè¯·ç¨åå†è¯•æˆ–ç®€åŒ–é—®é¢˜ã€‚"
        logger.warning("Agent response timeout.")
    except Exception as e:
        bot_msg = f"å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"
    history[-1][1] = bot_msg  # æ›´æ–°æœ€åä¸€æ¡å›å¤
    return history, history

# æ„å»º Gradio ç•Œé¢
with gr.Blocks() as demo:
    gr.Markdown("## ç³–åŒ»åŠ©æ‰‹ ğŸ©¸ â€” æŠ¥å‘Šæ‘˜è¦ä¸ç–‘é—®è§£ç­”")
    with gr.Row():
        with gr.Column(scale=2):
            report_input = gr.Textbox(
                label="æ£€éªŒæŠ¥å‘Šï¼ˆçº¯æ–‡æœ¬ï¼‰",
                placeholder="å°†æ£€éªŒæŠ¥å‘Šæ–‡å­—ç²˜è´´åœ¨æ­¤å¤„",
                lines=6
            )
            parse_btn = gr.Button("è§£ææŠ¥å‘Šè¦ç‚¹")
            summary_output = gr.Textbox(
                label="æŠ¥å‘Šæ‘˜è¦",
                interactive=False,
                lines=6
            )
            user_input = gr.Textbox(
                label="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜",
                placeholder="å¦‚ï¼šæˆ‘æœ€è¿‘å£æ¸´ã€å¤šå°¿ï¼Œæœ‰å®¶æ—å²",
                lines=2
            )
            send_btn = gr.Button("å‘é€")
        with gr.Column(scale=3):
            chatbot = gr.Chatbot(label="å¯¹è¯è®°å½•")

    state = gr.State([])

    # è§£ææ‘˜è¦
    parse_btn.click(
        fn=parse_report,
        inputs=[report_input],
        outputs=[summary_output]
    )
    # å‘é€ç–‘é—®
    send_btn.click(
        fn=answer_question,
        inputs=[summary_output, user_input, state],
        outputs=[chatbot, state]
    )
    user_input.submit(
        fn=answer_question,
        inputs=[summary_output, user_input, state],
        outputs=[chatbot, state]
    )

if __name__ == "__main__":
    demo.launch(inbrowser=True)
